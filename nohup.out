[I 16:26:06.390 NotebookApp] The port 8908 is already in use, trying another port.
[I 16:26:06.390 NotebookApp] The port 8909 is already in use, trying another port.
[I 16:26:06.390 NotebookApp] The port 8910 is already in use, trying another port.
[I 16:26:06.391 NotebookApp] The port 8911 is already in use, trying another port.
[I 16:26:06.391 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 16:26:06.391 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 16:26:06.391 NotebookApp] http://ip-172-31-11-83:8912/
[I 16:26:06.391 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 16:31:41.399 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 16:31:41.399 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 16:31:41.399 NotebookApp] http://ip-172-31-11-83:8908/
[I 16:31:41.399 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 16:31:45.955 NotebookApp] 302 GET / (118.219.28.24) 0.490000ms
[I 10:54:25.728 NotebookApp] Using EnvironmentKernelSpecManager...
[I 10:54:25.728 NotebookApp] Started periodic updates of the kernel list (every 3 minutes).
[I 10:54:25.938 NotebookApp] The port 8906 is already in use, trying another port.
[I 10:54:25.938 NotebookApp] Serving notebooks from local directory: /home/ubuntu/git/noise-data-platform
[I 10:54:25.939 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 10:54:25.939 NotebookApp] http://ip-172-31-11-83:8907/
[I 10:54:25.939 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 10:54:25.944 NotebookApp] Starting initial scan of virtual environments...
[I 10:54:29.902 NotebookApp] Found new kernels in environments: conda_pytorch_p38, conda_mxnet_p37, conda_spark_start, conda_anaconda3, conda_python3, conda_tensorflow2_p38, conda_aws_neuron_pytorch_p36, conda_amazonei_mxnet_p36, conda_sample_test, conda_aws_neuron_tensorflow_p36, conda_aws_neuron_mxnet_p36
[I 10:59:03.751 NotebookApp] Using EnvironmentKernelSpecManager...
[I 10:59:03.751 NotebookApp] Started periodic updates of the kernel list (every 3 minutes).
[I 10:59:03.962 NotebookApp] Serving notebooks from local directory: /home/ubuntu/git/noise-data-platform
[I 10:59:03.962 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 10:59:03.962 NotebookApp] http://ip-172-31-11-83:8905/
[I 10:59:03.962 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 10:59:03.966 NotebookApp] Starting initial scan of virtual environments...
[I 10:59:05.869 NotebookApp] Found new kernels in environments: conda_aws_neuron_pytorch_p36, conda_mxnet_p37, conda_anaconda3, conda_amazonei_mxnet_p36, conda_aws_neuron_mxnet_p36, conda_aws_neuron_tensorflow_p36, conda_tensorflow2_p38, conda_spark_start, conda_pytorch_p38, conda_sample_test, conda_python3
[I 10:59:09.657 NotebookApp] 302 GET / (175.118.53.87) 0.670000ms
[W 10:59:09.682 NotebookApp] Clearing invalid/expired login cookie username-15-168-145-74-8905
[W 10:59:09.683 NotebookApp] Clearing invalid/expired login cookie username-15-168-145-74-8905
[I 10:59:09.683 NotebookApp] 302 GET /tree? (175.118.53.87) 1.880000ms
[W 10:59:21.303 NotebookApp] 401 POST /login?next=%2Ftree%3F (175.118.53.87) 50.420000ms referer=http://15.168.145.74:8905/login?next=%2Ftree%3F
[I 10:59:24.193 NotebookApp] 302 POST /login?next=%2Ftree%3F (175.118.53.87) 36.980000ms
[W 10:59:24.768 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 10:59:24.768 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_python3 cannot be found!
[W 17:44:42.241 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_python3 cannot be found!
[I 17:44:58.194 NotebookApp] 302 GET / (175.118.53.87) 0.450000ms
[W 17:44:58.498 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_python3 cannot be found!
[I 18:46:04.049 NotebookApp] Creating new notebook in /EB
[W 18:46:07.567 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_python3 cannot be found!
[W 18:46:07.743 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 18:46:08.054 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[I 18:46:08.063 NotebookApp] Kernel started: 7a5feb5c-200f-42e6-855e-4c1fff113407, name: conda_spark_start
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:47:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:48:07.781 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:50:07.774 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:51:55.835 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:51:56.472 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:51:56.525 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:51:56.918 NotebookApp] Replaying 7 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:52:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:52:07.785 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:52:52.331 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:52:53.267 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:52:53.330 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:52:53.838 NotebookApp] Replaying 7 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:53:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:54:03.226 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:04.059 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:54:04.105 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:04.547 NotebookApp] Replaying 7 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:54:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:54:07.784 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:54:59.030 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:59.465 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:54:59.521 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:59.977 NotebookApp] Replaying 4 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:55:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:56:07.789 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:57:23.922 NotebookApp] Kernel interrupted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:57:27.551 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:57:30.183 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:57:30.232 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:57:30.233 NotebookApp] Replaying 1 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:57:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:58:07.826 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 13:58:06.177 NotebookApp] [nb_conda_kernels] enabled, 11 kernels found
[I 13:58:06.413 NotebookApp] Loading IPython parallel extension
[W 2025-02-12 13:58:06.518 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[W 2025-02-12 13:58:06.521 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.522 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[I 2025-02-12 13:58:06.528 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/python3/lib/python3.8/site-packages/jupyterlab
[I 2025-02-12 13:58:06.528 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/python3/share/jupyter/lab
[I 13:58:06.688 NotebookApp] [nb_conda] enabled
[I 13:58:06.688 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 13:58:06.689 NotebookApp] Jupyter Notebook 6.4.6 is running at:
[I 13:58:06.689 NotebookApp] http://ip-172-31-11-83:8908/
[I 13:58:06.689 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 13:58:14.496 NotebookApp] Kernel started: fd530838-558b-40ea-a8d7-5a5e69d1511b, name: conda-env-python3-py
[I 13:59:21.568 NotebookApp] Starting buffering for fd530838-558b-40ea-a8d7-5a5e69d1511b:86d9ff7800144e848ff152dd27fd808e
[I 13:59:28.431 NotebookApp] Starting buffering for fd530838-558b-40ea-a8d7-5a5e69d1511b:456650c6d132472b82bfae8257056dc6
[C 13:59:37.616 NotebookApp] received signal 15, stopping
[I 13:59:37.617 NotebookApp] Shutting down 1 kernel
[I 13:59:37.617 NotebookApp] Kernel shutdown: fd530838-558b-40ea-a8d7-5a5e69d1511b
[I 13:59:37.720 NotebookApp] Shutting down 0 terminals
[I 13:59:44.213 NotebookApp] [nb_conda_kernels] enabled, 11 kernels found
[I 13:59:44.449 NotebookApp] Loading IPython parallel extension
[W 2025-02-12 13:59:44.552 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[W 2025-02-12 13:59:44.554 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.554 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[I 2025-02-12 13:59:44.561 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/python3/lib/python3.8/site-packages/jupyterlab
[I 2025-02-12 13:59:44.561 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/python3/share/jupyter/lab
[I 13:59:44.719 NotebookApp] [nb_conda] enabled
[I 13:59:44.720 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 13:59:44.720 NotebookApp] Jupyter Notebook 6.4.6 is running at:
[I 13:59:44.720 NotebookApp] http://ip-172-31-11-83:8908/
[I 13:59:44.720 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 13:59:54.349 NotebookApp] Kernel started: ae5cdd9f-ca3a-43b1-9944-af5d82db5e4c, name: conda-env-python3-py
[I 13:59:57.947 NotebookApp] Starting buffering for ae5cdd9f-ca3a-43b1-9944-af5d82db5e4c:a2fee474bc864e9f9f7339fe81973c85
[I 13:59:57.949 NotebookApp] Kernel shutdown: ae5cdd9f-ca3a-43b1-9944-af5d82db5e4c
[I 13:59:58.098 NotebookApp] Kernel started: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728, name: python3
[I 14:01:54.348 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:21:54.485 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:23:28.966 NotebookApp] Kernel interrupted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:23:54.405 NotebookApp] Saving file at /ES/Untitled.ipynb
25/02/12 14:24:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:24:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 14:25:54.510 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:27:54.449 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:31:54.511 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:32:03.039 NotebookApp] Kernel interrupted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:32:27.496 NotebookApp] Starting buffering for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:32:27.735 NotebookApp] Kernel restarted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:32:27.824 NotebookApp] Restoring connection for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:32:28.829 NotebookApp] Replaying 3 buffered messages
25/02/12 14:32:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:32:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 14:32:42.830 NotebookApp] Kernel interrupted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:33:54.469 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:35:06.993 NotebookApp] Starting buffering for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:35:07.237 NotebookApp] Kernel restarted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:35:07.308 NotebookApp] Restoring connection for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:35:07.805 NotebookApp] Replaying 15 buffered messages
25/02/12 14:35:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:35:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/12 14:35:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 14:35:54.448 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:36:33.812 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:37:07.699 NotebookApp] 302 GET /notebooks/ES/json%ED%8C%8C%EC%9D%BC%EC%97%85%EB%A1%9C%EB%93%9C%ED%85%8C%EC%8A%A4%ED%8A%B8.ipynb (52.23.236.252) 0.610000ms
[W 14:37:53.595 NotebookApp] Notebook ES/json파일업로드테스트.ipynb is not trusted
[I 14:38:33.311 NotebookApp] Kernel restarted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
25/02/12 14:38:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:38:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 14:39:54.504 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
