[I 16:26:06.390 NotebookApp] The port 8908 is already in use, trying another port.
[I 16:26:06.390 NotebookApp] The port 8909 is already in use, trying another port.
[I 16:26:06.390 NotebookApp] The port 8910 is already in use, trying another port.
[I 16:26:06.391 NotebookApp] The port 8911 is already in use, trying another port.
[I 16:26:06.391 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 16:26:06.391 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 16:26:06.391 NotebookApp] http://ip-172-31-11-83:8912/
[I 16:26:06.391 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 16:31:41.399 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 16:31:41.399 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 16:31:41.399 NotebookApp] http://ip-172-31-11-83:8908/
[I 16:31:41.399 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 16:31:45.955 NotebookApp] 302 GET / (118.219.28.24) 0.490000ms
[I 10:54:25.728 NotebookApp] Using EnvironmentKernelSpecManager...
[I 10:54:25.728 NotebookApp] Started periodic updates of the kernel list (every 3 minutes).
[I 10:54:25.938 NotebookApp] The port 8906 is already in use, trying another port.
[I 10:54:25.938 NotebookApp] Serving notebooks from local directory: /home/ubuntu/git/noise-data-platform
[I 10:54:25.939 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 10:54:25.939 NotebookApp] http://ip-172-31-11-83:8907/
[I 10:54:25.939 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 10:54:25.944 NotebookApp] Starting initial scan of virtual environments...
[I 10:54:29.902 NotebookApp] Found new kernels in environments: conda_pytorch_p38, conda_mxnet_p37, conda_spark_start, conda_anaconda3, conda_python3, conda_tensorflow2_p38, conda_aws_neuron_pytorch_p36, conda_amazonei_mxnet_p36, conda_sample_test, conda_aws_neuron_tensorflow_p36, conda_aws_neuron_mxnet_p36
[I 10:59:03.751 NotebookApp] Using EnvironmentKernelSpecManager...
[I 10:59:03.751 NotebookApp] Started periodic updates of the kernel list (every 3 minutes).
[I 10:59:03.962 NotebookApp] Serving notebooks from local directory: /home/ubuntu/git/noise-data-platform
[I 10:59:03.962 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 10:59:03.962 NotebookApp] http://ip-172-31-11-83:8905/
[I 10:59:03.962 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 10:59:03.966 NotebookApp] Starting initial scan of virtual environments...
[I 10:59:05.869 NotebookApp] Found new kernels in environments: conda_aws_neuron_pytorch_p36, conda_mxnet_p37, conda_anaconda3, conda_amazonei_mxnet_p36, conda_aws_neuron_mxnet_p36, conda_aws_neuron_tensorflow_p36, conda_tensorflow2_p38, conda_spark_start, conda_pytorch_p38, conda_sample_test, conda_python3
[I 10:59:09.657 NotebookApp] 302 GET / (175.118.53.87) 0.670000ms
[W 10:59:09.682 NotebookApp] Clearing invalid/expired login cookie username-15-168-145-74-8905
[W 10:59:09.683 NotebookApp] Clearing invalid/expired login cookie username-15-168-145-74-8905
[I 10:59:09.683 NotebookApp] 302 GET /tree? (175.118.53.87) 1.880000ms
[W 10:59:21.303 NotebookApp] 401 POST /login?next=%2Ftree%3F (175.118.53.87) 50.420000ms referer=http://15.168.145.74:8905/login?next=%2Ftree%3F
[I 10:59:24.193 NotebookApp] 302 POST /login?next=%2Ftree%3F (175.118.53.87) 36.980000ms
[W 10:59:24.768 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 10:59:24.768 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 10:59:24.769 NotebookApp] Kernelspec name conda_python3 cannot be found!
[W 17:44:42.241 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 17:44:42.242 NotebookApp] Kernelspec name conda_python3 cannot be found!
[I 17:44:58.194 NotebookApp] 302 GET / (175.118.53.87) 0.450000ms
[W 17:44:58.498 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 17:44:58.498 NotebookApp] Kernelspec name conda_python3 cannot be found!
[I 18:46:04.049 NotebookApp] Creating new notebook in /EB
[W 18:46:07.567 NotebookApp] Kernelspec name conda_aws_neuron_pytorch_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_mxnet_p37 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_anaconda3 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_amazonei_mxnet_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_aws_neuron_mxnet_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_aws_neuron_tensorflow_p36 cannot be found!
[W 18:46:07.567 NotebookApp] Kernelspec name conda_tensorflow2_p38 cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_pytorch_p38 cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_sample_test cannot be found!
[W 18:46:07.568 NotebookApp] Kernelspec name conda_python3 cannot be found!
[W 18:46:07.743 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[W 18:46:08.054 NotebookApp] Kernelspec name conda_spark_start cannot be found!
[I 18:46:08.063 NotebookApp] Kernel started: 7a5feb5c-200f-42e6-855e-4c1fff113407, name: conda_spark_start
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:47:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:48:07.781 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:50:07.774 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:51:55.835 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:51:56.472 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:51:56.525 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:51:56.918 NotebookApp] Replaying 7 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:52:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:52:07.785 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:52:52.331 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:52:53.267 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:52:53.330 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:52:53.838 NotebookApp] Replaying 7 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:53:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:54:03.226 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:04.059 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:54:04.105 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:04.547 NotebookApp] Replaying 7 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:54:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:54:07.784 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:54:59.030 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:59.465 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:54:59.521 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:54:59.977 NotebookApp] Replaying 4 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:55:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:56:07.789 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 18:57:23.922 NotebookApp] Kernel interrupted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:57:27.551 NotebookApp] Starting buffering for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:57:30.183 NotebookApp] Kernel restarted: 7a5feb5c-200f-42e6-855e-4c1fff113407
[I 18:57:30.232 NotebookApp] Restoring connection for 7a5feb5c-200f-42e6-855e-4c1fff113407:a14ba4ee622f48fa85bae8c6dc8dd12b
[I 18:57:30.233 NotebookApp] Replaying 1 buffered messages
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: _moduleraw: line 1: syntax error: unexpected end of file
bash: error importing function definition for `_moduleraw'
bash: switchml: line 1: syntax error: unexpected end of file
bash: error importing function definition for `switchml'
25/02/08 18:57:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
[I 18:58:07.826 NotebookApp] Saving file at /EB/Untitled.ipynb
[I 13:58:06.177 NotebookApp] [nb_conda_kernels] enabled, 11 kernels found
[I 13:58:06.413 NotebookApp] Loading IPython parallel extension
[W 2025-02-12 13:58:06.518 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[W 2025-02-12 13:58:06.521 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.521 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:58:06.522 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[I 2025-02-12 13:58:06.528 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/python3/lib/python3.8/site-packages/jupyterlab
[I 2025-02-12 13:58:06.528 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/python3/share/jupyter/lab
[I 13:58:06.688 NotebookApp] [nb_conda] enabled
[I 13:58:06.688 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 13:58:06.689 NotebookApp] Jupyter Notebook 6.4.6 is running at:
[I 13:58:06.689 NotebookApp] http://ip-172-31-11-83:8908/
[I 13:58:06.689 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 13:58:14.496 NotebookApp] Kernel started: fd530838-558b-40ea-a8d7-5a5e69d1511b, name: conda-env-python3-py
[I 13:59:21.568 NotebookApp] Starting buffering for fd530838-558b-40ea-a8d7-5a5e69d1511b:86d9ff7800144e848ff152dd27fd808e
[I 13:59:28.431 NotebookApp] Starting buffering for fd530838-558b-40ea-a8d7-5a5e69d1511b:456650c6d132472b82bfae8257056dc6
[C 13:59:37.616 NotebookApp] received signal 15, stopping
[I 13:59:37.617 NotebookApp] Shutting down 1 kernel
[I 13:59:37.617 NotebookApp] Kernel shutdown: fd530838-558b-40ea-a8d7-5a5e69d1511b
[I 13:59:37.720 NotebookApp] Shutting down 0 terminals
[I 13:59:44.213 NotebookApp] [nb_conda_kernels] enabled, 11 kernels found
[I 13:59:44.449 NotebookApp] Loading IPython parallel extension
[W 2025-02-12 13:59:44.552 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[W 2025-02-12 13:59:44.554 LabApp] 'ip' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.554 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] 'port' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] 'password' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.
[W 2025-02-12 13:59:44.555 LabApp] Config option `kernel_spec_manager_class` not recognized by `LabApp`.
[I 2025-02-12 13:59:44.561 LabApp] JupyterLab extension loaded from /home/ubuntu/anaconda3/envs/python3/lib/python3.8/site-packages/jupyterlab
[I 2025-02-12 13:59:44.561 LabApp] JupyterLab application directory is /home/ubuntu/anaconda3/envs/python3/share/jupyter/lab
[I 13:59:44.719 NotebookApp] [nb_conda] enabled
[I 13:59:44.720 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 13:59:44.720 NotebookApp] Jupyter Notebook 6.4.6 is running at:
[I 13:59:44.720 NotebookApp] http://ip-172-31-11-83:8908/
[I 13:59:44.720 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 13:59:54.349 NotebookApp] Kernel started: ae5cdd9f-ca3a-43b1-9944-af5d82db5e4c, name: conda-env-python3-py
[I 13:59:57.947 NotebookApp] Starting buffering for ae5cdd9f-ca3a-43b1-9944-af5d82db5e4c:a2fee474bc864e9f9f7339fe81973c85
[I 13:59:57.949 NotebookApp] Kernel shutdown: ae5cdd9f-ca3a-43b1-9944-af5d82db5e4c
[I 13:59:58.098 NotebookApp] Kernel started: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728, name: python3
[I 14:01:54.348 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:21:54.485 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:23:28.966 NotebookApp] Kernel interrupted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:23:54.405 NotebookApp] Saving file at /ES/Untitled.ipynb
25/02/12 14:24:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:24:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 14:25:54.510 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:27:54.449 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:31:54.511 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:32:03.039 NotebookApp] Kernel interrupted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:32:27.496 NotebookApp] Starting buffering for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:32:27.735 NotebookApp] Kernel restarted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:32:27.824 NotebookApp] Restoring connection for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:32:28.829 NotebookApp] Replaying 3 buffered messages
25/02/12 14:32:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:32:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[I 14:32:42.830 NotebookApp] Kernel interrupted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:33:54.469 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:35:06.993 NotebookApp] Starting buffering for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:35:07.237 NotebookApp] Kernel restarted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 14:35:07.308 NotebookApp] Restoring connection for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[I 14:35:07.805 NotebookApp] Replaying 15 buffered messages
25/02/12 14:35:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:35:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/12 14:35:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 14:35:54.448 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:36:33.812 NotebookApp] Saving file at /ES/Untitled.ipynb
[I 14:37:07.699 NotebookApp] 302 GET /notebooks/ES/json%ED%8C%8C%EC%9D%BC%EC%97%85%EB%A1%9C%EB%93%9C%ED%85%8C%EC%8A%A4%ED%8A%B8.ipynb (52.23.236.252) 0.610000ms
[W 14:37:53.595 NotebookApp] Notebook ES/json파일업로드테스트.ipynb is not trusted
[I 14:38:33.311 NotebookApp] Kernel restarted: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
25/02/12 14:38:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 14:38:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [I 14:39:54.504 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[I 14:59:54.372 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[I 15:01:54.479 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[I 15:05:54.480 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[I 15:07:54.465 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[I 15:29:54.477 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[W 15:40:22.187 NotebookApp] Notebook ES/json파일업로드테스트.ipynb is not trusted
[W 15:41:06.221 NotebookApp] 404 GET /api/contents/git/noise-data-platform/ES?type=directory&_=1739261180316 (118.219.28.24): No such file or directory: git/noise-data-platform/ES
[W 15:41:06.221 NotebookApp] No such file or directory: git/noise-data-platform/ES
[W 15:41:06.221 NotebookApp] 404 GET /api/contents/git/noise-data-platform/ES?type=directory&_=1739261180316 (118.219.28.24) 0.820000ms referer=http://15.168.145.74:8908/tree/git/noise-data-platform/ES
[I 16:45:18.821 NotebookApp] Starting buffering for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:a2fee474bc864e9f9f7339fe81973c85
[W 16:45:20.085 NotebookApp] Notebook ES/json파일업로드테스트.ipynb is not trusted
[I 17:49:19.379 NotebookApp] Starting buffering for 2dc6debc-1b3b-40dd-8e92-45ac7bc53728:48b9e38414bc4f8c87e1647eb64bd99b
[C 19:00:01.139 NotebookApp] received signal 15, stopping
[I 19:00:01.140 NotebookApp] Shutting down 1 kernel
[I 19:00:01.141 NotebookApp] Kernel shutdown: 2dc6debc-1b3b-40dd-8e92-45ac7bc53728
[I 19:00:01.245 NotebookApp] Shutting down 0 terminals
[I 11:02:08.603 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 11:02:08.603 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 11:02:08.603 NotebookApp] http://ip-172-31-11-83:8908/
[I 11:02:08.603 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[W 11:02:16.262 NotebookApp] 404 GET /notebooks/git/noise-data-platform/ES/1.%20Sample_test%20(%EC%9D%8C%EC%84%B1%ED%8C%8C%EC%9D%BC%EC%A0%81%EC%9E%AC).ipynb (118.219.28.24): No such file or directory: git/noise-data-platform/ES/1. Sample_test (음성파일적재).ipynb
[W 11:02:16.283 NotebookApp] 404 GET /notebooks/git/noise-data-platform/ES/1.%20Sample_test%20(%EC%9D%8C%EC%84%B1%ED%8C%8C%EC%9D%BC%EC%A0%81%EC%9E%AC).ipynb (118.219.28.24) 21.830000ms referer=http://15.168.145.74:8908/tree/git/noise-data-platform/ES
[W 11:02:19.401 NotebookApp] 404 GET /api/contents/git/noise-data-platform/ES?type=directory&_=1739408469918 (118.219.28.24): No such file or directory: git/noise-data-platform/ES
[W 11:02:19.401 NotebookApp] No such file or directory: git/noise-data-platform/ES
[W 11:02:19.402 NotebookApp] 404 GET /api/contents/git/noise-data-platform/ES?type=directory&_=1739408469918 (118.219.28.24) 0.790000ms referer=http://15.168.145.74:8908/tree/git/noise-data-platform/ES
[W 11:02:20.274 NotebookApp] 404 GET /tree/git/noise-data-platform/ES (118.219.28.24) 1.140000ms referer=http://15.168.145.74:8908/notebooks/git/noise-data-platform/JW/hellohello.ipynb
[W 11:02:21.040 NotebookApp] 404 GET /tree/git/noise-data-platform/ES (118.219.28.24) 1.080000ms referer=http://15.168.145.74:8908/notebooks/git/noise-data-platform/JW/hellohello.ipynb
[I 11:02:27.035 NotebookApp] 302 GET / (118.219.28.24) 0.420000ms
[W 11:05:23.216 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 11:05:23.478 NotebookApp] Kernel started: 2ac3f0c0-b522-4945-ba81-23f355c8e19f, name: python3
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: afdc2f62-548d-4df1-92ce-370f96efb339
[I 11:07:23.942 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 11:07:23.943 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[W 13:20:00.083 NotebookApp] delete /ml_env_packages.txt
[W 13:20:00.087 NotebookApp] delete /ml_env_packages_conda.txt
[W 13:39:48.791 NotebookApp] delete /environment.txt
[W 13:39:48.793 NotebookApp] delete /environment.yml
[C 13:55:27.308 NotebookApp] received signal 15, stopping
[I 13:55:27.308 NotebookApp] Shutting down 1 kernel
[I 13:55:27.308 NotebookApp] Kernel shutdown: 2ac3f0c0-b522-4945-ba81-23f355c8e19f
[I 13:55:27.404 NotebookApp] Starting buffering for 2ac3f0c0-b522-4945-ba81-23f355c8e19f:d28e780c03f044fb87d1a0ad022fd52e
[I 13:55:27.420 NotebookApp] Shutting down 0 terminals
[I 13:55:43.761 NotebookApp] Serving notebooks from local directory: /home/lab08/git/noise-data-platform
[I 13:55:43.761 NotebookApp] Jupyter Notebook 6.4.10 is running at:
[I 13:55:43.761 NotebookApp] http://ip-172-31-11-83:8908/
[I 13:55:43.761 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 13:55:45.121 NotebookApp] 302 GET / (118.219.28.24) 0.440000ms
[W 13:55:55.573 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 13:55:55.806 NotebookApp] Kernel started: 10b30a51-ad0a-462e-a402-c1168493d90d, name: python3
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 36fb2c94-0bf0-41ac-a9c8-b596c5babc66
[I 13:55:59.106 NotebookApp] Kernel shutdown: 10b30a51-ad0a-462e-a402-c1168493d90d
[I 13:55:59.111 NotebookApp] Starting buffering for 10b30a51-ad0a-462e-a402-c1168493d90d:423a6b0b7069416d8ae09291e7f2ab64
[I 13:55:59.272 NotebookApp] Kernel started: 80ee7de9-9375-4884-820b-dda9e0404bfe, name: myenv
[W 13:56:55.451 NotebookApp] Notebook ES/json파일업로드테스트.ipynb is not trusted
[I 13:56:55.565 NotebookApp] Kernel started: 2372fb0f-0a0f-4e55-84c7-a43a6eb7c36c, name: python3
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: f6fc1776-e7d1-4997-ba33-ebc673ee1299
25/02/13 13:57:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/13 13:57:11 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2025-02-13 13:57:18.152780: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-02-13 13:57:18.209430: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-13 13:57:18.921056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[I 13:57:56.037 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 13:57:56.037 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[W 14:14:53.339 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 14:16:53.961 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 14:16:53.962 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[W 14:52:46.997 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 14:54:47.907 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 14:54:47.908 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
25/02/13 16:07:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/13 16:07:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/13 16:07:51 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/13 16:07:51 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[I 16:08:55.628 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[W 16:53:45.320 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 16:55:46.247 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 16:55:46.248 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 16:57:46.339 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 16:57:46.339 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: e824a5ad-a956-434e-be25-02fbf0edcd2e
[I 17:21:45.926 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 17:21:45.927 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[I 17:23:46.079 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 17:23:46.079 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[W 17:27:24.210 NotebookApp] Notebook EB/1.자동차_2_json.ipynb is not trusted
[I 17:27:24.305 NotebookApp] Kernel started: 57141624-6a5a-496a-969b-307c2a481615, name: python3
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 582276dc-fa84-4b96-b2d8-a85a042a5032
[Stage 0:>                                                          (0 + 1) / 1][I 17:28:52.135 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
                                                                                [I 17:29:24.902 NotebookApp] Saving file at /EB/1.자동차_2_json.ipynb
[I 17:30:52.880 NotebookApp] Saving file at /ES/json파일업로드테스트.ipynb
[I 17:38:56.446 NotebookApp] Starting buffering for 57141624-6a5a-496a-969b-307c2a481615:6f12eaf4cc8543098899a803c7025f22
[I 17:39:22.836 NotebookApp] Starting buffering for 2372fb0f-0a0f-4e55-84c7-a43a6eb7c36c:cc2efbe9f83d469f8f7f3ec0acac8ba6
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: e68fba93-8c36-4a77-9fac-84ba4cb55fec
[I 17:39:29.562 NotebookApp] Starting buffering for 57141624-6a5a-496a-969b-307c2a481615:576c6cb39d8c4943803e982c7beb7908
[W 17:39:33.323 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
[IPKernelApp] ERROR | No such comm target registered: jupyter.widget.control
[IPKernelApp] WARNING | No such comm: 4ade94c2-eb17-4ab4-93ef-f45edc2af508
[I 17:41:34.120 NotebookApp] Saving file at /ES/1. Sample_test (음성파일적재).ipynb
[W 17:41:34.121 NotebookApp] Notebook ES/1. Sample_test (음성파일적재).ipynb is not trusted
