{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7926c766-e106-4176-a2db-35d94993f785",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN + 분류 모델 (학습데이터셋: final_training_data_sampled_1500_category_03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b31494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f722e487-4466-472e-ae6a-e1a9e43d2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d7094-d02b-46b2-a460-b12032b2ab08",
   "metadata": {},
   "source": [
    "# 데이터 준비 및 전처리\n",
    "- combined_result.csv (raw_data + 기타소음4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bccf207-e413-4cf2-abb2-a1d19ebf0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 준비\n",
    "df = pd.read_csv(\"final_training_data_sampled_1500_category_03.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6611f2-2ac5-4d66-9e02-c842cc528164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16500, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "793a4052-596c-4fdc-a417-acbf98fec260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of            mfcc_1      mfcc_2     mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0     -470.270660  156.080307  -6.749740 -16.042160  -3.874907   3.941253   \n",
       "1     -460.384155  180.129044  11.334196  11.868873  -4.974021   6.809534   \n",
       "2     -449.925873  171.836411   2.386576  22.721798  -1.736225   6.190225   \n",
       "3     -455.254059  181.796967   9.294571  10.934427  -4.022550   5.616430   \n",
       "4     -288.710693  213.676682 -41.471188 -42.155613 -33.182774 -24.146034   \n",
       "...           ...         ...        ...        ...        ...        ...   \n",
       "16495 -393.683350  112.838249  78.327019  53.811954  39.379765  30.957418   \n",
       "16496 -378.663422  134.701477  79.424789  49.431168  34.184185  28.483421   \n",
       "16497 -461.395416  121.848076  89.299278  62.308353  43.243988  29.191967   \n",
       "16498 -493.641632  157.938858  25.808128   8.548108  40.262383  37.603741   \n",
       "16499 -355.461334  135.167755  75.394547  46.334789  31.962107  27.757746   \n",
       "\n",
       "          mfcc_7     mfcc_8     mfcc_9    mfcc_10  ...   mfcc_42   mfcc_43  \\\n",
       "0       1.167268  -1.400177   7.833455  13.149685  ...  0.034769 -1.235597   \n",
       "1       2.316912  -1.110410   4.471837  -3.005936  ... -1.849761 -1.397370   \n",
       "2       3.721608  -0.588912   3.393057  -2.117786  ... -1.431983 -1.919918   \n",
       "3       3.438021  -0.869901   4.194035  -2.174661  ... -1.573517 -0.977286   \n",
       "4     -11.305103  -7.085775   5.217451   0.280858  ... -0.855696 -0.679235   \n",
       "...          ...        ...        ...        ...  ...       ...       ...   \n",
       "16495  25.438747  18.227119   7.888356  -0.895374  ... -1.249327 -0.159267   \n",
       "16496  25.417803  18.336458   5.979050  -2.790854  ... -1.456156  0.373588   \n",
       "16497  21.168716  16.137163   9.661809   2.718837  ... -2.819749 -2.933694   \n",
       "16498  25.108101  26.178638  21.627758   6.950775  ...  1.102074  1.538854   \n",
       "16499  26.231886  19.167902   5.832071  -3.864456  ... -0.747523  0.966861   \n",
       "\n",
       "        mfcc_44   mfcc_45   mfcc_46   mfcc_47   mfcc_48   mfcc_49   mfcc_50  \\\n",
       "0     -0.301899 -0.251646 -1.192489 -1.056090 -1.439306 -2.125451 -0.912826   \n",
       "1     -0.326148 -0.544115  1.193453  1.776051  1.189161  1.103796 -0.418156   \n",
       "2     -1.287754  0.694544  0.912185  1.730576  1.207210  0.895003  0.309655   \n",
       "3     -0.867862  0.113248  1.195198  1.583179  1.669622  0.705978  0.036158   \n",
       "4     -0.401828  0.197711 -1.456901 -2.260075 -0.780481 -0.710989 -2.045619   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "16495  0.412751  0.696340  0.956642  1.115927  1.119452  0.800756  0.471013   \n",
       "16496  0.569235  0.766947  0.116607 -0.001870  0.072865 -0.502700 -0.355066   \n",
       "16497 -2.321804 -1.213236 -0.292092  0.086035  0.065583 -0.230239 -0.578410   \n",
       "16498  1.880772  0.560185 -1.180385 -0.375596  1.385499  1.470733  0.498940   \n",
       "16499  0.835240  0.745447  0.931719  1.765759  2.125631  1.541811  0.741804   \n",
       "\n",
       "       category_03  \n",
       "0                개  \n",
       "1                개  \n",
       "2                개  \n",
       "3                개  \n",
       "4                개  \n",
       "...            ...  \n",
       "16495          항타기  \n",
       "16496          항타기  \n",
       "16497          항타기  \n",
       "16498          항타기  \n",
       "16499          항타기  \n",
       "\n",
       "[16500 rows x 51 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c448cb8d-1917-46c5-82fa-90d5f06e14be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "고양이       1500\n",
       "발전기       1500\n",
       "이륜차경적     1500\n",
       "차량경적      1500\n",
       "차량사이렌     1500\n",
       "개         1500\n",
       "이륜차주행음    1500\n",
       "항타기       1500\n",
       "콘크리트펌프    1500\n",
       "차량주행음     1500\n",
       "공구        1500\n",
       "Name: category_03, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_03'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308502d-9670-4b08-b69b-d8215ad47bda",
   "metadata": {},
   "source": [
    "# 소음 카테고리 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54da68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소음 카테고리 변환 함수\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values  # MFCC 특징 값\n",
    "y = df['label'].values       # 레이블\n",
    "\n",
    "# 레이블 인코딩 (문자 → 숫자)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)  # One-hot 인코딩\n",
    "\n",
    "# 데이터셋 분할 (훈련:테스트 = 80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# CNN 입력 형태로 변환 (3D 텐서: 샘플 수 x 시간 축 x 특징 수)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d880a78-41ae-45c3-8d5c-8bf150f26b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      9000\n",
       "이륜차경적     1500\n",
       "차량경적      1500\n",
       "차량사이렌     1500\n",
       "이륜차주행음    1500\n",
       "차량주행음     1500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bd144-7474-4715-b7d7-c63b75b4b493",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b410af-f7c3-49e4-84e0-51c07d1a9fcc",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6939f1-4285-4765-8f19-219a246dd0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')  # 출력층 (카테고리 수만큼 출력)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed9bb7d-d678-4942-89f4-ed400b1f0471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.8414 - accuracy: 0.7455 - val_loss: 0.3060 - val_accuracy: 0.9082\n",
      "Epoch 2/30\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.3907 - accuracy: 0.8707 - val_loss: 0.2217 - val_accuracy: 0.9339\n",
      "Epoch 3/30\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.3082 - accuracy: 0.8927 - val_loss: 0.2065 - val_accuracy: 0.9385\n",
      "Epoch 4/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.2632 - accuracy: 0.9092 - val_loss: 0.1547 - val_accuracy: 0.9473\n",
      "Epoch 5/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.2291 - accuracy: 0.9177 - val_loss: 0.1446 - val_accuracy: 0.9552\n",
      "Epoch 6/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.2139 - accuracy: 0.9267 - val_loss: 0.1311 - val_accuracy: 0.9591\n",
      "Epoch 7/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1910 - accuracy: 0.9318 - val_loss: 0.1314 - val_accuracy: 0.9555\n",
      "Epoch 8/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1829 - accuracy: 0.9367 - val_loss: 0.1308 - val_accuracy: 0.9542\n",
      "Epoch 9/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1749 - accuracy: 0.9399 - val_loss: 0.1175 - val_accuracy: 0.9594\n",
      "Epoch 10/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1678 - accuracy: 0.9428 - val_loss: 0.1159 - val_accuracy: 0.9576\n",
      "Epoch 11/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1576 - accuracy: 0.9438 - val_loss: 0.1209 - val_accuracy: 0.9591\n",
      "Epoch 12/30\n",
      "413/413 [==============================] - 3s 6ms/step - loss: 0.1563 - accuracy: 0.9468 - val_loss: 0.1102 - val_accuracy: 0.9630\n",
      "Epoch 13/30\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.1386 - accuracy: 0.9503 - val_loss: 0.1093 - val_accuracy: 0.9594\n",
      "Epoch 14/30\n",
      "413/413 [==============================] - 3s 7ms/step - loss: 0.1364 - accuracy: 0.9520 - val_loss: 0.0990 - val_accuracy: 0.9661\n",
      "Epoch 15/30\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 0.1336 - accuracy: 0.9519 - val_loss: 0.1023 - val_accuracy: 0.9648\n",
      "Epoch 16/30\n",
      "413/413 [==============================] - 3s 8ms/step - loss: 0.1314 - accuracy: 0.9532 - val_loss: 0.1037 - val_accuracy: 0.9639\n",
      "Epoch 17/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1214 - accuracy: 0.9564 - val_loss: 0.1100 - val_accuracy: 0.9600\n",
      "Epoch 18/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1240 - accuracy: 0.9570 - val_loss: 0.1027 - val_accuracy: 0.9652\n",
      "Epoch 19/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1182 - accuracy: 0.9615 - val_loss: 0.1028 - val_accuracy: 0.9612\n",
      "Epoch 20/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1153 - accuracy: 0.9603 - val_loss: 0.1000 - val_accuracy: 0.9639\n",
      "Epoch 21/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1158 - accuracy: 0.9595 - val_loss: 0.0972 - val_accuracy: 0.9682\n",
      "Epoch 22/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1122 - accuracy: 0.9577 - val_loss: 0.1010 - val_accuracy: 0.9661\n",
      "Epoch 23/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1029 - accuracy: 0.9627 - val_loss: 0.1068 - val_accuracy: 0.9630\n",
      "Epoch 24/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1032 - accuracy: 0.9623 - val_loss: 0.0930 - val_accuracy: 0.9676\n",
      "Epoch 25/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1072 - accuracy: 0.9632 - val_loss: 0.1052 - val_accuracy: 0.9642\n",
      "Epoch 26/30\n",
      "413/413 [==============================] - 4s 11ms/step - loss: 0.1030 - accuracy: 0.9645 - val_loss: 0.0927 - val_accuracy: 0.9706\n",
      "Epoch 27/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1015 - accuracy: 0.9630 - val_loss: 0.1082 - val_accuracy: 0.9658\n",
      "Epoch 28/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.1006 - accuracy: 0.9642 - val_loss: 0.1077 - val_accuracy: 0.9658\n",
      "Epoch 29/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.0999 - accuracy: 0.9665 - val_loss: 0.1002 - val_accuracy: 0.9639\n",
      "Epoch 30/30\n",
      "413/413 [==============================] - 4s 10ms/step - loss: 0.0918 - accuracy: 0.9673 - val_loss: 0.1037 - val_accuracy: 0.9667\n",
      "104/104 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9667\n",
      "Accuracy: 0.9667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.99      0.99      0.99      1800\n",
      "       이륜차경적       0.99      0.95      0.97       300\n",
      "      이륜차주행음       0.96      0.81      0.88       300\n",
      "        차량경적       0.94      0.98      0.96       300\n",
      "       차량사이렌       0.98      0.97      0.97       300\n",
      "       차량주행음       0.82      0.97      0.89       300\n",
      "\n",
      "    accuracy                           0.97      3300\n",
      "   macro avg       0.95      0.94      0.94      3300\n",
      "weighted avg       0.97      0.97      0.97      3300\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1790    0    5    0    2    3]\n",
      " [   1  284    0   15    0    0]\n",
      " [   6    0  242    0    1   51]\n",
      " [   1    2    1  294    0    2]\n",
      " [   1    0    1    0  290    8]\n",
      " [   1    0    4    3    2  290]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 예측된 클래스 인덱스\n",
    "y_true_classes = np.argmax(y_test, axis=1)  # 실제 클래스 인덱스\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ff2ab9-b827-4f95-9002-48a342848c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 cnn1_6classfication_category_03.h5 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('cnn1_6classfication_category_03.h5') \n",
    "print(\"모델이 cnn1_6classfication_category_03.h5 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e878f00a-a7f2-4f86-a0ac-deef7fe31981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 206,086\n",
      "Trainable params: 206,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loaded Model Accuracy: 0.9667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.99      0.99      0.99      1800\n",
      "       이륜차경적       0.99      0.95      0.97       300\n",
      "      이륜차주행음       0.96      0.81      0.88       300\n",
      "        차량경적       0.94      0.98      0.96       300\n",
      "       차량사이렌       0.98      0.97      0.97       300\n",
      "       차량주행음       0.82      0.97      0.89       300\n",
      "\n",
      "    accuracy                           0.97      3300\n",
      "   macro avg       0.95      0.94      0.94      3300\n",
      "weighted avg       0.97      0.97      0.97      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = keras.models.load_model('cnn1_6classfication_category_03.h5')\n",
    "\n",
    "# 모델 구조 확인\n",
    "loaded_model.summary()\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2450d97-c64c-4dc0-ad4f-a5f8d227a1ea",
   "metadata": {},
   "source": [
    "### 성능 개선\n",
    "- 배치 정규화 (Batch Normalisation) 레이어 Conv1D 와 Dense 추가\n",
    "- 앙상블 기법 적용\n",
    "- ReduceROnPlateau 콜백 사용 \n",
    "- 모델 구조 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a581fe-7609-46c3-9938-b440534101d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 9ms/step - loss: 0.6574 - accuracy: 0.7635 - val_loss: 0.3456 - val_accuracy: 0.8705\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4213 - accuracy: 0.8452 - val_loss: 0.2862 - val_accuracy: 0.8932\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3591 - accuracy: 0.8679 - val_loss: 0.2484 - val_accuracy: 0.9018\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3188 - accuracy: 0.8846 - val_loss: 0.2217 - val_accuracy: 0.9201\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2950 - accuracy: 0.8916 - val_loss: 0.2260 - val_accuracy: 0.9223\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2737 - accuracy: 0.8981 - val_loss: 0.1890 - val_accuracy: 0.9287\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2703 - accuracy: 0.9008 - val_loss: 0.1977 - val_accuracy: 0.9259\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2524 - accuracy: 0.9085 - val_loss: 0.1931 - val_accuracy: 0.9284\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2371 - accuracy: 0.9148 - val_loss: 0.1728 - val_accuracy: 0.9345\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2349 - accuracy: 0.9135 - val_loss: 0.1836 - val_accuracy: 0.9334\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2203 - accuracy: 0.9190 - val_loss: 0.1835 - val_accuracy: 0.9343\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.2146 - accuracy: 0.9203 - val_loss: 0.1710 - val_accuracy: 0.9415\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2043 - accuracy: 0.9274 - val_loss: 0.1630 - val_accuracy: 0.9404\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2098 - accuracy: 0.9243 - val_loss: 0.1640 - val_accuracy: 0.9434\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1907 - accuracy: 0.9297 - val_loss: 0.1680 - val_accuracy: 0.9417\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1970 - accuracy: 0.9278 - val_loss: 0.1600 - val_accuracy: 0.9448\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1882 - accuracy: 0.9312 - val_loss: 0.1661 - val_accuracy: 0.9387\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1863 - accuracy: 0.9320 - val_loss: 0.1643 - val_accuracy: 0.9431\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1789 - accuracy: 0.9334 - val_loss: 0.1546 - val_accuracy: 0.9451\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1784 - accuracy: 0.9351 - val_loss: 0.1534 - val_accuracy: 0.9448\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1761 - accuracy: 0.9357 - val_loss: 0.1527 - val_accuracy: 0.9448\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1648 - accuracy: 0.9393 - val_loss: 0.1490 - val_accuracy: 0.9454\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1675 - accuracy: 0.9376 - val_loss: 0.1644 - val_accuracy: 0.9440\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1626 - accuracy: 0.9401 - val_loss: 0.1484 - val_accuracy: 0.9473\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1667 - accuracy: 0.9403 - val_loss: 0.1573 - val_accuracy: 0.9434\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1675 - accuracy: 0.9378 - val_loss: 0.1431 - val_accuracy: 0.9487\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1541 - accuracy: 0.9440 - val_loss: 0.1449 - val_accuracy: 0.9501\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1486 - accuracy: 0.9441 - val_loss: 0.1485 - val_accuracy: 0.9476\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1476 - accuracy: 0.9459 - val_loss: 0.1450 - val_accuracy: 0.9523\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1490 - accuracy: 0.9469 - val_loss: 0.1417 - val_accuracy: 0.9495\n",
      "Training model 2/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 9ms/step - loss: 0.6385 - accuracy: 0.7668 - val_loss: 0.3575 - val_accuracy: 0.8730\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4178 - accuracy: 0.8465 - val_loss: 0.2588 - val_accuracy: 0.9049\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3523 - accuracy: 0.8726 - val_loss: 0.2361 - val_accuracy: 0.9168\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3230 - accuracy: 0.8823 - val_loss: 0.2385 - val_accuracy: 0.9065\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2884 - accuracy: 0.8930 - val_loss: 0.2170 - val_accuracy: 0.9182\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 5s 12ms/step - loss: 0.2729 - accuracy: 0.9034 - val_loss: 0.1922 - val_accuracy: 0.9276\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2671 - accuracy: 0.9043 - val_loss: 0.1984 - val_accuracy: 0.9276\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2491 - accuracy: 0.9095 - val_loss: 0.1816 - val_accuracy: 0.9362\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2441 - accuracy: 0.9133 - val_loss: 0.2064 - val_accuracy: 0.9212\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2252 - accuracy: 0.9172 - val_loss: 0.1635 - val_accuracy: 0.9429\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.2213 - accuracy: 0.9212 - val_loss: 0.1648 - val_accuracy: 0.9379\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2084 - accuracy: 0.9238 - val_loss: 0.1668 - val_accuracy: 0.9406\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2064 - accuracy: 0.9251 - val_loss: 0.1600 - val_accuracy: 0.9401\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1971 - accuracy: 0.9265 - val_loss: 0.1706 - val_accuracy: 0.9429\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1911 - accuracy: 0.9313 - val_loss: 0.1495 - val_accuracy: 0.9492\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1895 - accuracy: 0.9295 - val_loss: 0.1731 - val_accuracy: 0.9365\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1828 - accuracy: 0.9344 - val_loss: 0.1547 - val_accuracy: 0.9420\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1774 - accuracy: 0.9358 - val_loss: 0.1932 - val_accuracy: 0.9295\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1805 - accuracy: 0.9334 - val_loss: 0.1503 - val_accuracy: 0.9448\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1682 - accuracy: 0.9363 - val_loss: 0.1403 - val_accuracy: 0.9506\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1691 - accuracy: 0.9392 - val_loss: 0.1443 - val_accuracy: 0.9467\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1598 - accuracy: 0.9399 - val_loss: 0.1464 - val_accuracy: 0.9445\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1629 - accuracy: 0.9397 - val_loss: 0.1511 - val_accuracy: 0.9492\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1600 - accuracy: 0.9393 - val_loss: 0.1601 - val_accuracy: 0.9434\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1570 - accuracy: 0.9429 - val_loss: 0.1528 - val_accuracy: 0.9415\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1388 - accuracy: 0.9484 - val_loss: 0.1420 - val_accuracy: 0.9495\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1321 - accuracy: 0.9503 - val_loss: 0.1372 - val_accuracy: 0.9517\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1284 - accuracy: 0.9527 - val_loss: 0.1354 - val_accuracy: 0.9537\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1281 - accuracy: 0.9521 - val_loss: 0.1406 - val_accuracy: 0.9481\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1226 - accuracy: 0.9523 - val_loss: 0.1372 - val_accuracy: 0.9528\n",
      "Training model 3/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 8s 14ms/step - loss: 0.6384 - accuracy: 0.7664 - val_loss: 0.3415 - val_accuracy: 0.8777\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.4134 - accuracy: 0.8442 - val_loss: 0.2737 - val_accuracy: 0.9074\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.3545 - accuracy: 0.8685 - val_loss: 0.2595 - val_accuracy: 0.9090\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.3161 - accuracy: 0.8886 - val_loss: 0.2190 - val_accuracy: 0.9229\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2981 - accuracy: 0.8908 - val_loss: 0.2309 - val_accuracy: 0.9135\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2724 - accuracy: 0.9009 - val_loss: 0.2171 - val_accuracy: 0.9223\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2615 - accuracy: 0.9057 - val_loss: 0.2084 - val_accuracy: 0.9232\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2551 - accuracy: 0.9089 - val_loss: 0.1918 - val_accuracy: 0.9326\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2388 - accuracy: 0.9143 - val_loss: 0.1815 - val_accuracy: 0.9345\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2325 - accuracy: 0.9136 - val_loss: 0.1788 - val_accuracy: 0.9351\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2308 - accuracy: 0.9193 - val_loss: 0.1744 - val_accuracy: 0.9384\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2173 - accuracy: 0.9197 - val_loss: 0.1599 - val_accuracy: 0.9431\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.2189 - accuracy: 0.9213 - val_loss: 0.1631 - val_accuracy: 0.9434\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.2064 - accuracy: 0.9272 - val_loss: 0.1727 - val_accuracy: 0.9373\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1995 - accuracy: 0.9270 - val_loss: 0.1554 - val_accuracy: 0.9423\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1908 - accuracy: 0.9293 - val_loss: 0.1735 - val_accuracy: 0.9387\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1874 - accuracy: 0.9327 - val_loss: 0.1515 - val_accuracy: 0.9476\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1869 - accuracy: 0.9338 - val_loss: 0.1552 - val_accuracy: 0.9429\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1848 - accuracy: 0.9316 - val_loss: 0.1518 - val_accuracy: 0.9442\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1788 - accuracy: 0.9342 - val_loss: 0.1400 - val_accuracy: 0.9503\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1752 - accuracy: 0.9344 - val_loss: 0.1510 - val_accuracy: 0.9487\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1742 - accuracy: 0.9363 - val_loss: 0.1449 - val_accuracy: 0.9501\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1659 - accuracy: 0.9404 - val_loss: 0.1461 - val_accuracy: 0.9459\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1657 - accuracy: 0.9372 - val_loss: 0.1578 - val_accuracy: 0.9420\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1653 - accuracy: 0.9399 - val_loss: 0.1500 - val_accuracy: 0.9490\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1439 - accuracy: 0.9461 - val_loss: 0.1404 - val_accuracy: 0.9498\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 6s 14ms/step - loss: 0.1419 - accuracy: 0.9459 - val_loss: 0.1414 - val_accuracy: 0.9512\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1333 - accuracy: 0.9519 - val_loss: 0.1390 - val_accuracy: 0.9515\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1302 - accuracy: 0.9527 - val_loss: 0.1401 - val_accuracy: 0.9506\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1326 - accuracy: 0.9498 - val_loss: 0.1363 - val_accuracy: 0.9498\n",
      "Ensemble Accuracy: 0.9528\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.98      0.95      0.97       373\n",
      "       이륜차경적       0.98      0.95      0.97       912\n",
      "      이륜차주행음       0.95      0.96      0.96       947\n",
      "        차량경적       0.93      0.95      0.94       638\n",
      "       차량사이렌       0.98      0.96      0.97       398\n",
      "       차량주행음       0.88      0.92      0.90       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.95      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[356   1   9   0   3   4]\n",
      " [  0 869   2  41   0   0]\n",
      " [  5   0 913   0   1  28]\n",
      " [  1  19  11 605   1   1]\n",
      " [  2   0   3   2 382   9]\n",
      " [  0   0  26   0   1 310]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비 (기존 코드와 동일)\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 개선된 CNN 모델 정의\n",
    "def create_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(y_categorical.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "def create_ensemble(num_models=3):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = create_model()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble = create_ensemble()\n",
    "\n",
    "# 학습률 스케줄링\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 모델 학습\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble):\n",
    "    print(f\"Training model {i+1}/{len(ensemble)}\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n",
    "    histories.append(history)\n",
    "\n",
    "# 앙상블 예측\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측\n",
    "y_pred_ensemble = ensemble_predict(ensemble, X_test)\n",
    "y_pred_classes = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7d6b35-e4bf-43a7-96bf-325ed92a19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 cnn2_6classfication_category_03.h5 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('cnn2_6classfication_category_03.h5')\n",
    "print(\"모델이 cnn2_6classfication_category_03.h5 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162f1311-650a-4f68-868f-7c2496d3ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 22, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 207,366\n",
      "Trainable params: 206,726\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Loaded Model Accuracy: 0.9498\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.97      0.95      0.96       373\n",
      "       이륜차경적       0.97      0.95      0.96       912\n",
      "      이륜차주행음       0.95      0.96      0.95       947\n",
      "        차량경적       0.93      0.95      0.94       638\n",
      "       차량사이렌       0.98      0.95      0.97       398\n",
      "       차량주행음       0.87      0.91      0.89       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.95      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = keras.models.load_model('cnn2_6classfication_category_03.h5')\n",
    "\n",
    "# 모델 구조 확인\n",
    "loaded_model.summary()\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29b170-5241-4a2f-9b93-1dac0a62470c",
   "metadata": {},
   "source": [
    "### 차량 주행음 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c22183d-f4f1-4e33-8b88-6f2489b53d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1708 - accuracy: 0.9373 - val_loss: 0.1589 - val_accuracy: 0.9431\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1698 - accuracy: 0.9366 - val_loss: 0.1829 - val_accuracy: 0.9337\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1639 - accuracy: 0.9399 - val_loss: 0.2034 - val_accuracy: 0.9251\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1550 - accuracy: 0.9392 - val_loss: 0.1602 - val_accuracy: 0.9395\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1606 - accuracy: 0.9402 - val_loss: 0.1718 - val_accuracy: 0.9359\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1525 - accuracy: 0.9397 - val_loss: 0.1475 - val_accuracy: 0.9534\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1543 - accuracy: 0.9395 - val_loss: 0.1786 - val_accuracy: 0.9315\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1433 - accuracy: 0.9449 - val_loss: 0.1599 - val_accuracy: 0.9434\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1497 - accuracy: 0.9419 - val_loss: 0.1948 - val_accuracy: 0.9237\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1378 - accuracy: 0.9444 - val_loss: 0.1597 - val_accuracy: 0.9423\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1337 - accuracy: 0.9467 - val_loss: 0.1559 - val_accuracy: 0.9454\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1334 - accuracy: 0.9493 - val_loss: 0.1492 - val_accuracy: 0.9473\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1153 - accuracy: 0.9538 - val_loss: 0.1530 - val_accuracy: 0.9445\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1199 - accuracy: 0.9528 - val_loss: 0.1487 - val_accuracy: 0.9465\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1152 - accuracy: 0.9534 - val_loss: 0.1522 - val_accuracy: 0.9465\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1167 - accuracy: 0.9528 - val_loss: 0.1511 - val_accuracy: 0.9454\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1135 - accuracy: 0.9544 - val_loss: 0.1500 - val_accuracy: 0.9479\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1062 - accuracy: 0.9570 - val_loss: 0.1466 - val_accuracy: 0.9481\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1071 - accuracy: 0.9583 - val_loss: 0.1505 - val_accuracy: 0.9459\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1082 - accuracy: 0.9560 - val_loss: 0.1505 - val_accuracy: 0.9473\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1086 - accuracy: 0.9586 - val_loss: 0.1520 - val_accuracy: 0.9448\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1066 - accuracy: 0.9582 - val_loss: 0.1492 - val_accuracy: 0.9467\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1048 - accuracy: 0.9562 - val_loss: 0.1468 - val_accuracy: 0.9512\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1098 - accuracy: 0.9560 - val_loss: 0.1480 - val_accuracy: 0.9481\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1022 - accuracy: 0.9581 - val_loss: 0.1506 - val_accuracy: 0.9470\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1076 - accuracy: 0.9571 - val_loss: 0.1495 - val_accuracy: 0.9470\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1028 - accuracy: 0.9602 - val_loss: 0.1474 - val_accuracy: 0.9490\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1003 - accuracy: 0.9589 - val_loss: 0.1517 - val_accuracy: 0.9462\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1041 - accuracy: 0.9586 - val_loss: 0.1520 - val_accuracy: 0.9484\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1030 - accuracy: 0.9580 - val_loss: 0.1494 - val_accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "                                                 y=np.argmax(y_train, axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weight_dict, callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af8a72cd-d2c6-43a2-8521-20ab07400cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 9ms/step - loss: 0.6919 - accuracy: 0.7610 - val_loss: 0.3852 - val_accuracy: 0.8519\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4618 - accuracy: 0.8320 - val_loss: 0.2790 - val_accuracy: 0.9015\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3836 - accuracy: 0.8620 - val_loss: 0.2397 - val_accuracy: 0.9140\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3442 - accuracy: 0.8751 - val_loss: 0.2540 - val_accuracy: 0.9032\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3140 - accuracy: 0.8867 - val_loss: 0.2248 - val_accuracy: 0.9154\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2880 - accuracy: 0.8969 - val_loss: 0.2289 - val_accuracy: 0.9121\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2869 - accuracy: 0.8978 - val_loss: 0.2573 - val_accuracy: 0.9001\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2638 - accuracy: 0.9015 - val_loss: 0.1815 - val_accuracy: 0.9334\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2601 - accuracy: 0.9072 - val_loss: 0.1760 - val_accuracy: 0.9370\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2425 - accuracy: 0.9100 - val_loss: 0.2188 - val_accuracy: 0.9168\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2301 - accuracy: 0.9171 - val_loss: 0.2051 - val_accuracy: 0.9248\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2259 - accuracy: 0.9175 - val_loss: 0.1836 - val_accuracy: 0.9326\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2126 - accuracy: 0.9227 - val_loss: 0.1958 - val_accuracy: 0.9298\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2223 - accuracy: 0.9179 - val_loss: 0.1689 - val_accuracy: 0.9387\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2020 - accuracy: 0.9240 - val_loss: 0.1853 - val_accuracy: 0.9301\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2018 - accuracy: 0.9217 - val_loss: 0.2228 - val_accuracy: 0.9129\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1905 - accuracy: 0.9295 - val_loss: 0.1935 - val_accuracy: 0.9257\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1915 - accuracy: 0.9267 - val_loss: 0.1707 - val_accuracy: 0.9393\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1804 - accuracy: 0.9301 - val_loss: 0.1605 - val_accuracy: 0.9415\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1818 - accuracy: 0.9304 - val_loss: 0.1646 - val_accuracy: 0.9401\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1833 - accuracy: 0.9297 - val_loss: 0.1743 - val_accuracy: 0.9384\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1853 - accuracy: 0.9320 - val_loss: 0.1700 - val_accuracy: 0.9395\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1737 - accuracy: 0.9338 - val_loss: 0.1638 - val_accuracy: 0.9359\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1694 - accuracy: 0.9329 - val_loss: 0.1666 - val_accuracy: 0.9401\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1531 - accuracy: 0.9401 - val_loss: 0.1535 - val_accuracy: 0.9451\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1461 - accuracy: 0.9424 - val_loss: 0.1465 - val_accuracy: 0.9476\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1348 - accuracy: 0.9461 - val_loss: 0.1457 - val_accuracy: 0.9465\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1334 - accuracy: 0.9485 - val_loss: 0.1484 - val_accuracy: 0.9462\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1277 - accuracy: 0.9492 - val_loss: 0.1451 - val_accuracy: 0.9476\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1323 - accuracy: 0.9480 - val_loss: 0.1527 - val_accuracy: 0.9454\n",
      "Training model 2/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 9ms/step - loss: 0.7113 - accuracy: 0.7535 - val_loss: 0.3364 - val_accuracy: 0.8693\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4524 - accuracy: 0.8375 - val_loss: 0.3191 - val_accuracy: 0.8838\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3888 - accuracy: 0.8596 - val_loss: 0.2369 - val_accuracy: 0.9162\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3459 - accuracy: 0.8744 - val_loss: 0.2601 - val_accuracy: 0.9035\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3121 - accuracy: 0.8884 - val_loss: 0.2471 - val_accuracy: 0.9051\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3021 - accuracy: 0.8937 - val_loss: 0.2267 - val_accuracy: 0.9154\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2850 - accuracy: 0.8941 - val_loss: 0.2046 - val_accuracy: 0.9270\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2667 - accuracy: 0.9021 - val_loss: 0.1883 - val_accuracy: 0.9298\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2470 - accuracy: 0.9097 - val_loss: 0.1844 - val_accuracy: 0.9343\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2368 - accuracy: 0.9151 - val_loss: 0.1709 - val_accuracy: 0.9365\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2371 - accuracy: 0.9130 - val_loss: 0.2138 - val_accuracy: 0.9196\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2273 - accuracy: 0.9165 - val_loss: 0.1783 - val_accuracy: 0.9365\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2201 - accuracy: 0.9202 - val_loss: 0.1925 - val_accuracy: 0.9315\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2148 - accuracy: 0.9194 - val_loss: 0.1741 - val_accuracy: 0.9365\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2067 - accuracy: 0.9236 - val_loss: 0.1581 - val_accuracy: 0.9431\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1929 - accuracy: 0.9282 - val_loss: 0.1848 - val_accuracy: 0.9298\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1876 - accuracy: 0.9290 - val_loss: 0.1878 - val_accuracy: 0.9315\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1951 - accuracy: 0.9255 - val_loss: 0.1596 - val_accuracy: 0.9440\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1875 - accuracy: 0.9279 - val_loss: 0.1657 - val_accuracy: 0.9398\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1837 - accuracy: 0.9295 - val_loss: 0.1615 - val_accuracy: 0.9381\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1598 - accuracy: 0.9378 - val_loss: 0.1613 - val_accuracy: 0.9387\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1545 - accuracy: 0.9423 - val_loss: 0.1434 - val_accuracy: 0.9492\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1489 - accuracy: 0.9419 - val_loss: 0.1491 - val_accuracy: 0.9451\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1489 - accuracy: 0.9422 - val_loss: 0.1492 - val_accuracy: 0.9451\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1444 - accuracy: 0.9440 - val_loss: 0.1533 - val_accuracy: 0.9417\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1404 - accuracy: 0.9457 - val_loss: 0.1478 - val_accuracy: 0.9459\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1404 - accuracy: 0.9448 - val_loss: 0.1381 - val_accuracy: 0.9526\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1357 - accuracy: 0.9469 - val_loss: 0.1483 - val_accuracy: 0.9431\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1303 - accuracy: 0.9493 - val_loss: 0.1436 - val_accuracy: 0.9473\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1330 - accuracy: 0.9462 - val_loss: 0.1534 - val_accuracy: 0.9437\n",
      "Training model 3/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 9ms/step - loss: 0.6966 - accuracy: 0.7510 - val_loss: 0.4049 - val_accuracy: 0.8447\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.4586 - accuracy: 0.8327 - val_loss: 0.2640 - val_accuracy: 0.9046\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.3873 - accuracy: 0.8602 - val_loss: 0.2508 - val_accuracy: 0.9082\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.3483 - accuracy: 0.8730 - val_loss: 0.2870 - val_accuracy: 0.8943\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.3279 - accuracy: 0.8837 - val_loss: 0.2060 - val_accuracy: 0.9279\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2940 - accuracy: 0.8939 - val_loss: 0.2032 - val_accuracy: 0.9273\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2883 - accuracy: 0.8939 - val_loss: 0.1998 - val_accuracy: 0.9298\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.2644 - accuracy: 0.9030 - val_loss: 0.2171 - val_accuracy: 0.9184\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2523 - accuracy: 0.9061 - val_loss: 0.1980 - val_accuracy: 0.9287\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2459 - accuracy: 0.9107 - val_loss: 0.2426 - val_accuracy: 0.9076\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2368 - accuracy: 0.9131 - val_loss: 0.1751 - val_accuracy: 0.9406\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2210 - accuracy: 0.9149 - val_loss: 0.1897 - val_accuracy: 0.9345\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2177 - accuracy: 0.9176 - val_loss: 0.2060 - val_accuracy: 0.9226\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2081 - accuracy: 0.9218 - val_loss: 0.1948 - val_accuracy: 0.9304\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2115 - accuracy: 0.9232 - val_loss: 0.1954 - val_accuracy: 0.9270\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1990 - accuracy: 0.9238 - val_loss: 0.2019 - val_accuracy: 0.9240\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1822 - accuracy: 0.9299 - val_loss: 0.1690 - val_accuracy: 0.9390\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1625 - accuracy: 0.9387 - val_loss: 0.1650 - val_accuracy: 0.9401\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1616 - accuracy: 0.9374 - val_loss: 0.1713 - val_accuracy: 0.9384\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1600 - accuracy: 0.9363 - val_loss: 0.1653 - val_accuracy: 0.9412\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1543 - accuracy: 0.9408 - val_loss: 0.1769 - val_accuracy: 0.9354\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1527 - accuracy: 0.9412 - val_loss: 0.1610 - val_accuracy: 0.9423\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1549 - accuracy: 0.9392 - val_loss: 0.1585 - val_accuracy: 0.9423\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1484 - accuracy: 0.9432 - val_loss: 0.1627 - val_accuracy: 0.9404\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1434 - accuracy: 0.9462 - val_loss: 0.1731 - val_accuracy: 0.9359\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1458 - accuracy: 0.9438 - val_loss: 0.1591 - val_accuracy: 0.9404\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1438 - accuracy: 0.9443 - val_loss: 0.1579 - val_accuracy: 0.9437\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1448 - accuracy: 0.9451 - val_loss: 0.1520 - val_accuracy: 0.9459\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1464 - accuracy: 0.9453 - val_loss: 0.1554 - val_accuracy: 0.9426\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1383 - accuracy: 0.9476 - val_loss: 0.1556 - val_accuracy: 0.9437\n",
      "Ensemble Accuracy: 0.9470\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.96      0.97      0.96       373\n",
      "       이륜차경적       0.99      0.95      0.97       912\n",
      "      이륜차주행음       0.97      0.91      0.94       947\n",
      "        차량경적       0.93      0.96      0.95       638\n",
      "       차량사이렌       0.98      0.97      0.98       398\n",
      "       차량주행음       0.79      0.97      0.87       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.95      0.94      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[360   1   6   0   2   4]\n",
      " [  1 867   2  41   0   1]\n",
      " [ 11   0 862   0   2  72]\n",
      " [  1  10   9 613   1   4]\n",
      " [  2   0   1   2 386   7]\n",
      " [  0   0  10   0   1 326]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# 데이터 준비 (기존 코드와 동일)\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "                                                 y=np.argmax(y_train, axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 개선된 CNN 모델 정의\n",
    "def create_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(y_categorical.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "def create_ensemble(num_models=3):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = create_model()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble = create_ensemble()\n",
    "\n",
    "# 학습률 스케줄링\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 모델 학습\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble):\n",
    "    print(f\"Training model {i+1}/{len(ensemble)}\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), \n",
    "                        class_weight=class_weight_dict, callbacks=[reduce_lr])\n",
    "    histories.append(history)\n",
    "\n",
    "# 앙상블 예측\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측\n",
    "y_pred_ensemble = ensemble_predict(ensemble, X_test)\n",
    "y_pred_classes = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9a06bd2-9f57-4e2c-b76d-7fbc2548b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 저장\n",
    "# model.save('updated2_cnn_model_6classfication.h5')\n",
    "# print(\"모델이 updated2_cnn_model_6classfication.h5 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceee206-4011-4bca-b270-a367d5011bcb",
   "metadata": {},
   "source": [
    "### 차량주행음 - Precision 과 f1-score 개선\n",
    "- 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31fd3266-6cc3-45ed-a3fb-d159af0e02ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.6045 - accuracy: 0.7782 - val_loss: 0.3691 - val_accuracy: 0.8696\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.3752 - accuracy: 0.8652 - val_loss: 0.2540 - val_accuracy: 0.9071\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.3187 - accuracy: 0.8835 - val_loss: 0.2551 - val_accuracy: 0.9037\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2666 - accuracy: 0.9068 - val_loss: 0.2031 - val_accuracy: 0.9215\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2505 - accuracy: 0.9109 - val_loss: 0.2044 - val_accuracy: 0.9218\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2291 - accuracy: 0.9186 - val_loss: 0.1806 - val_accuracy: 0.9334\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2204 - accuracy: 0.9220 - val_loss: 0.1836 - val_accuracy: 0.9323\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 7s 10ms/step - loss: 0.1985 - accuracy: 0.9297 - val_loss: 0.1829 - val_accuracy: 0.9368\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.1908 - accuracy: 0.9328 - val_loss: 0.1866 - val_accuracy: 0.9320\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1864 - accuracy: 0.9329 - val_loss: 0.1884 - val_accuracy: 0.9309\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1833 - accuracy: 0.9348 - val_loss: 0.1643 - val_accuracy: 0.9395\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1706 - accuracy: 0.9385 - val_loss: 0.1958 - val_accuracy: 0.9282\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1650 - accuracy: 0.9401 - val_loss: 0.1602 - val_accuracy: 0.9412\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1560 - accuracy: 0.9449 - val_loss: 0.1595 - val_accuracy: 0.9465\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1522 - accuracy: 0.9467 - val_loss: 0.1629 - val_accuracy: 0.9420\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1540 - accuracy: 0.9442 - val_loss: 0.1717 - val_accuracy: 0.9393\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1435 - accuracy: 0.9488 - val_loss: 0.1643 - val_accuracy: 0.9370\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1460 - accuracy: 0.9465 - val_loss: 0.1751 - val_accuracy: 0.9356\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1406 - accuracy: 0.9498 - val_loss: 0.1587 - val_accuracy: 0.9440\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1334 - accuracy: 0.9523 - val_loss: 0.1543 - val_accuracy: 0.9442\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1338 - accuracy: 0.9534 - val_loss: 0.1650 - val_accuracy: 0.9404\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1359 - accuracy: 0.9522 - val_loss: 0.1569 - val_accuracy: 0.9456\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1300 - accuracy: 0.9539 - val_loss: 0.1378 - val_accuracy: 0.9551\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1251 - accuracy: 0.9546 - val_loss: 0.1712 - val_accuracy: 0.9415\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1168 - accuracy: 0.9570 - val_loss: 0.1535 - val_accuracy: 0.9448\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1242 - accuracy: 0.9552 - val_loss: 0.1518 - val_accuracy: 0.9501\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1189 - accuracy: 0.9566 - val_loss: 0.1454 - val_accuracy: 0.9501\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1142 - accuracy: 0.9593 - val_loss: 0.1662 - val_accuracy: 0.9426\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1035 - accuracy: 0.9630 - val_loss: 0.1458 - val_accuracy: 0.9503\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.0973 - accuracy: 0.9644 - val_loss: 0.1538 - val_accuracy: 0.9487\n",
      "Training model 2/3\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 7s 8ms/step - loss: 0.5896 - accuracy: 0.7835 - val_loss: 0.2826 - val_accuracy: 0.8968\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.3730 - accuracy: 0.8661 - val_loss: 0.3191 - val_accuracy: 0.8810\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.3124 - accuracy: 0.8887 - val_loss: 0.2666 - val_accuracy: 0.9012\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 7s 10ms/step - loss: 0.2662 - accuracy: 0.9050 - val_loss: 0.1979 - val_accuracy: 0.9279\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2467 - accuracy: 0.9131 - val_loss: 0.1975 - val_accuracy: 0.9245\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2350 - accuracy: 0.9183 - val_loss: 0.2063 - val_accuracy: 0.9229\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2158 - accuracy: 0.9222 - val_loss: 0.1784 - val_accuracy: 0.9362\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.2007 - accuracy: 0.9299 - val_loss: 0.2248 - val_accuracy: 0.9179\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1957 - accuracy: 0.9295 - val_loss: 0.1969 - val_accuracy: 0.9301\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1818 - accuracy: 0.9364 - val_loss: 0.1637 - val_accuracy: 0.9404\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1815 - accuracy: 0.9355 - val_loss: 0.1552 - val_accuracy: 0.9487\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1739 - accuracy: 0.9398 - val_loss: 0.1828 - val_accuracy: 0.9365\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1661 - accuracy: 0.9414 - val_loss: 0.1759 - val_accuracy: 0.9384\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1620 - accuracy: 0.9411 - val_loss: 0.1755 - val_accuracy: 0.9348\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1489 - accuracy: 0.9462 - val_loss: 0.1832 - val_accuracy: 0.9318\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1540 - accuracy: 0.9444 - val_loss: 0.1592 - val_accuracy: 0.9412\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1362 - accuracy: 0.9506 - val_loss: 0.1541 - val_accuracy: 0.9451\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1250 - accuracy: 0.9554 - val_loss: 0.1581 - val_accuracy: 0.9434\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1182 - accuracy: 0.9590 - val_loss: 0.1643 - val_accuracy: 0.9415\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1171 - accuracy: 0.9596 - val_loss: 0.1521 - val_accuracy: 0.9481\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1161 - accuracy: 0.9600 - val_loss: 0.1498 - val_accuracy: 0.9448\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1149 - accuracy: 0.9588 - val_loss: 0.1533 - val_accuracy: 0.9479\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1105 - accuracy: 0.9604 - val_loss: 0.1531 - val_accuracy: 0.9473\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1096 - accuracy: 0.9607 - val_loss: 0.1530 - val_accuracy: 0.9448\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1052 - accuracy: 0.9628 - val_loss: 0.1489 - val_accuracy: 0.9487\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1045 - accuracy: 0.9635 - val_loss: 0.1539 - val_accuracy: 0.9456\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1060 - accuracy: 0.9622 - val_loss: 0.1581 - val_accuracy: 0.9426\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1054 - accuracy: 0.9616 - val_loss: 0.1465 - val_accuracy: 0.9481\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1023 - accuracy: 0.9635 - val_loss: 0.1552 - val_accuracy: 0.9445\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1051 - accuracy: 0.9631 - val_loss: 0.1485 - val_accuracy: 0.9492\n",
      "Training model 3/3\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.5774 - accuracy: 0.7869 - val_loss: 0.3087 - val_accuracy: 0.8902\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.3596 - accuracy: 0.8721 - val_loss: 0.2625 - val_accuracy: 0.8996\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 7s 10ms/step - loss: 0.3069 - accuracy: 0.8900 - val_loss: 0.2170 - val_accuracy: 0.9218\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.2753 - accuracy: 0.9026 - val_loss: 0.1975 - val_accuracy: 0.9320\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.2435 - accuracy: 0.9150 - val_loss: 0.2128 - val_accuracy: 0.9215\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.2273 - accuracy: 0.9195 - val_loss: 0.1735 - val_accuracy: 0.9365\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2146 - accuracy: 0.9243 - val_loss: 0.2003 - val_accuracy: 0.9293\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.2004 - accuracy: 0.9273 - val_loss: 0.1893 - val_accuracy: 0.9293\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1892 - accuracy: 0.9322 - val_loss: 0.1624 - val_accuracy: 0.9417\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1824 - accuracy: 0.9342 - val_loss: 0.1901 - val_accuracy: 0.9282\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1786 - accuracy: 0.9359 - val_loss: 0.1715 - val_accuracy: 0.9381\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1700 - accuracy: 0.9396 - val_loss: 0.1911 - val_accuracy: 0.9309\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1662 - accuracy: 0.9406 - val_loss: 0.1706 - val_accuracy: 0.9406\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1545 - accuracy: 0.9452 - val_loss: 0.1752 - val_accuracy: 0.9331\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1414 - accuracy: 0.9513 - val_loss: 0.1539 - val_accuracy: 0.9431\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1280 - accuracy: 0.9544 - val_loss: 0.1503 - val_accuracy: 0.9442\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1242 - accuracy: 0.9574 - val_loss: 0.1593 - val_accuracy: 0.9415\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1166 - accuracy: 0.9585 - val_loss: 0.1602 - val_accuracy: 0.9420\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1204 - accuracy: 0.9578 - val_loss: 0.1517 - val_accuracy: 0.9431\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 7s 10ms/step - loss: 0.1184 - accuracy: 0.9576 - val_loss: 0.1664 - val_accuracy: 0.9398\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1158 - accuracy: 0.9607 - val_loss: 0.1508 - val_accuracy: 0.9462\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1102 - accuracy: 0.9599 - val_loss: 0.1453 - val_accuracy: 0.9479\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1098 - accuracy: 0.9604 - val_loss: 0.1498 - val_accuracy: 0.9442\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1087 - accuracy: 0.9634 - val_loss: 0.1548 - val_accuracy: 0.9415\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1048 - accuracy: 0.9615 - val_loss: 0.1536 - val_accuracy: 0.9423\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1035 - accuracy: 0.9635 - val_loss: 0.1484 - val_accuracy: 0.9451\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1027 - accuracy: 0.9637 - val_loss: 0.1522 - val_accuracy: 0.9445\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1031 - accuracy: 0.9638 - val_loss: 0.1606 - val_accuracy: 0.9448\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1035 - accuracy: 0.9631 - val_loss: 0.1490 - val_accuracy: 0.9476\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1036 - accuracy: 0.9634 - val_loss: 0.1525 - val_accuracy: 0.9454\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "# 레이블 인코딩 및 데이터 분할\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 오버샘플링 적용 (훈련 데이터만)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y_train_categorical = to_categorical(y_train_resampled)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# 데이터 형태 변환\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# CNN 모델 정의\n",
    "def create_model():\n",
    "    inputs = Input(shape=(X_train_resampled.shape[1], 1))\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(y_test_categorical.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "def create_ensemble(num_models=3):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = create_model()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble = create_ensemble()\n",
    "\n",
    "# 학습률 스케줄링 콜백 정의\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 모델 학습 (오버샘플링된 데이터 사용)\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble):\n",
    "    print(f\"Training model {i+1}/{len(ensemble)}\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train_resampled, y_train_categorical,\n",
    "                        epochs=30,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_test, y_test_categorical),\n",
    "                        callbacks=[reduce_lr])\n",
    "    histories.append(history)\n",
    "\n",
    "# 앙상블 예측 함수 정의\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측 수행\n",
    "y_pred_ensemble = ensemble_predict(ensemble, X_test)\n",
    "\n",
    "# 클래스별로 가장 높은 확률을 가진\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f94fb2a0-4699-48f7-abe5-a6ab28b03f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9495\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.96      0.97      0.96       373\n",
      "       이륜차경적       0.98      0.95      0.97       912\n",
      "      이륜차주행음       0.96      0.93      0.95       947\n",
      "        차량경적       0.93      0.95      0.94       638\n",
      "       차량사이렌       0.98      0.96      0.97       398\n",
      "       차량주행음       0.83      0.96      0.89       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[360   1   7   0   3   2]\n",
      " [  1 868   2  41   0   0]\n",
      " [ 10   0 879   0   2  56]\n",
      " [  2  14  11 609   1   1]\n",
      " [  2   0   3   3 383   7]\n",
      " [  1   0  10   0   2 324]]\n"
     ]
    }
   ],
   "source": [
    "# 클래스별로 가장 높은 확률을 가진 클래스 인덱스를 선택\n",
    "y_pred_classes = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_true_classes = np.argmax(y_test_categorical, axis=1)\n",
    "\n",
    "# 정확도 계산 및 출력\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae53cb5a-27fd-49fe-a4b1-9c12873abd6f",
   "metadata": {},
   "source": [
    "# 새로운 wav 파일 분류 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d071eb4-2313-4fc6-8ea6-b9f9174a9ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 50, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 22, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 207,366\n",
      "Trainable params: 206,726\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9a30c0-5e9a-4f24-82f8-fbc631a4d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_audio(audio_path):\n",
    "    try:\n",
    "        # 음원 파일 로드\n",
    "        y, sr = librosa.load(audio_path, sr=44100)\n",
    "\n",
    "        # MFCC 특징 추출\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=50)\n",
    "\n",
    "        # 추출된 MFCC 특징의 평균값을 사용 (각 MFCC 차수별로 하나의 값)\n",
    "        mfccs_processed = np.mean(mfccs, axis=1)\n",
    "\n",
    "        # CNN 입력 형태로 변환 (3D 텐서)\n",
    "        new_data = mfccs_processed.reshape(1, -1, 1)\n",
    "\n",
    "        # 예측 수행\n",
    "        predicted_label_encoded = np.argmax(model.predict(new_data), axis=-1)[0]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio file: {e}\")\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962b8f05-fcc4-40a7-a041-4926b5a01b55",
   "metadata": {},
   "source": [
    "## 테스트 데이터셋 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e612265e-1c42-4f3c-bcc5-7daac780af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 206,086\n",
      "Trainable params: 206,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy: 0.1020\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           개       0.17      0.99      0.28        90\n",
      "         고양이       0.00      0.00      0.00        90\n",
      "          공구       0.01      0.01      0.01        90\n",
      "         발전기       0.00      0.00      0.00        90\n",
      "       이륜차경적       0.00      0.00      0.00        90\n",
      "      이륜차주행음       0.11      0.12      0.11        90\n",
      "        차량경적       0.00      0.00      0.00        90\n",
      "       차량사이렌       0.00      0.00      0.00        90\n",
      "       차량주행음       0.00      0.00      0.00        90\n",
      "      콘크리트펌프       0.00      0.00      0.00        90\n",
      "         항타기       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.10       990\n",
      "   macro avg       0.03      0.10      0.04       990\n",
      "weighted avg       0.03      0.10      0.04       990\n",
      "\n",
      "Confusion Matrix:\n",
      " [[89  0  1  0  0  0  0  0  0  0  0]\n",
      " [90  0  0  0  0  0  0  0  0  0  0]\n",
      " [86  0  1  1  1  1  0  0  0  0  0]\n",
      " [90  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 87  0  3  0  0  0  0  0  0  0]\n",
      " [ 2  0 75  1  1 11  0  0  0  0  0]\n",
      " [ 0  2  0 86  1  1  0  0  0  0  0]\n",
      " [ 1  0  1  0 88  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0 88  0  0  0  0  0]\n",
      " [89  0  0  0  0  1  0  0  0  0  0]\n",
      " [90  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. LabelEncoder 초기화\n",
    "label_encoder = LabelEncoder()\n",
    "df_train = pd.read_csv(\"final_training_data_sampled_1500_category_03.csv\", encoding='utf-8')\n",
    "label_encoder.fit(df_train['category_03'])\n",
    "\n",
    "# 2. 모델 로드\n",
    "loaded_model = load_model('cnn1_6classfication_category_03.h5')\n",
    "loaded_model.summary()\n",
    "\n",
    "# 3. 테스트 데이터 로드\n",
    "test_data_path = 'final_test_sampled_90_category_03.csv'\n",
    "df_test = pd.read_csv(test_data_path, encoding='utf-8')\n",
    "\n",
    "# 4. 테스트 데이터 전처리\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "X_test = df_test[feature_cols].values\n",
    "y_true = df_test['category_03'].values\n",
    "\n",
    "# CNN 입력 형태로 변환\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 5. 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = label_encoder.transform(y_true)\n",
    "\n",
    "# 6. 평가\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d750590d-206a-4ba9-afe5-abffbe1ebd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 206,086\n",
      "Trainable params: 206,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loaded Model Accuracy: 0.1020\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           개       0.17      0.99      0.28        90\n",
      "         고양이       0.00      0.00      0.00        90\n",
      "          공구       0.01      0.01      0.01        90\n",
      "         발전기       0.00      0.00      0.00        90\n",
      "       이륜차경적       0.00      0.00      0.00        90\n",
      "      이륜차주행음       0.11      0.12      0.11        90\n",
      "        차량경적       0.00      0.00      0.00        90\n",
      "       차량사이렌       0.00      0.00      0.00        90\n",
      "       차량주행음       0.00      0.00      0.00        90\n",
      "      콘크리트펌프       0.00      0.00      0.00        90\n",
      "         항타기       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.10       990\n",
      "   macro avg       0.03      0.10      0.04       990\n",
      "weighted avg       0.03      0.10      0.04       990\n",
      "\n",
      "Confusion Matrix:\n",
      " [[89  0  1  0  0  0  0  0  0  0  0]\n",
      " [90  0  0  0  0  0  0  0  0  0  0]\n",
      " [86  0  1  1  1  1  0  0  0  0  0]\n",
      " [90  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 87  0  3  0  0  0  0  0  0  0]\n",
      " [ 2  0 75  1  1 11  0  0  0  0  0]\n",
      " [ 0  2  0 86  1  1  0  0  0  0  0]\n",
      " [ 1  0  1  0 88  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0 88  0  0  0  0  0]\n",
      " [89  0  0  0  0  1  0  0  0  0  0]\n",
      " [90  0  0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import librosa\n",
    "\n",
    "# 1. 모델 로드\n",
    "loaded_model = load_model('cnn1_6classfication_category_03.h5')\n",
    "\n",
    "# 2. 모델 구조 확인\n",
    "loaded_model.summary()\n",
    "\n",
    "# 3. 레이블 인코더 준비\n",
    "label_encoder = LabelEncoder()\n",
    "df_train = pd.read_csv(\"final_training_data_sampled_1500_category_03.csv\", encoding='utf-8')\n",
    "label_encoder.fit(df_train['category_03'])\n",
    "\n",
    "# 4. 테스트 데이터 로드 및 전처리\n",
    "test_data_path = '/home/lab05/git/noise-data-platform/EB/final_test_sampled_90_category_03.csv'\n",
    "df_test = pd.read_csv(test_data_path, encoding='utf-8')\n",
    "\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "X_test = df_test[feature_cols].values\n",
    "y_true = df_test['category_03'].values\n",
    "\n",
    "# CNN 입력 형태로 변환 (3D 텐서)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = label_encoder.transform(y_true)\n",
    "\n",
    "# 5. 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 6. 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 7. 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698d007-e120-4a7f-8e58-b9f5c42014f5",
   "metadata": {},
   "source": [
    "## 기타소음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f180ef-d9a5-4f60-96ae-2ba57292bd9e",
   "metadata": {},
   "source": [
    "### 고양이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5f6d5a4-8249-4813-be6b-510b1e614ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:46<00:00,  5.94it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/동물/15.고양이\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_cat = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb3b05ae-f805-4b56-a9f2-dba96b86e90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      271\n",
       "이륜차주행음      1\n",
       "차량주행음       1\n",
       "차량사이렌       1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_cat['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f664effd-8c60-493c-ba28-623e11740e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 274\n",
      "'기타소음' Count: 271\n",
      "'기타소음' Ratio: 98.91%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_cat = len(results_df_cat)  # 전체 파일 개수\n",
    "etc_noise_count_cat = results_df_cat[results_df_cat['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_cat = (etc_noise_count_cat / total_files_cat) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_cat}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_cat}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_cat:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0ce5065-ce17-4897-8dfe-1101ba25bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CSV로 저장\n",
    "# results_df_cat.to_csv(\"cat.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'cat.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca8ad8",
   "metadata": {},
   "source": [
    "### 강아지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92ebccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 217/217 [00:54<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/동물/14.개\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_dog = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8851b253-db48-47ef-ad1a-6cecebb59f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      210\n",
       "차량사이렌       4\n",
       "이륜차주행음      2\n",
       "차량주행음       1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_dog['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "764059f8-07fc-4862-adc4-df50e8ea1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 217\n",
      "'기타소음' Count: 210\n",
      "'기타소음' Ratio: 96.77%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_dog = len(results_df_dog)  # 전체 파일 개수\n",
    "etc_noise_count_dog = results_df_dog[results_df_dog['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_dog = (etc_noise_count_dog / total_files_dog) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_dog}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_dog}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_dog:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "610bee9e-3845-48d6-9728-7cdc22a5f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_dog.to_csv(\"dog.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'dog.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033c4f5-a370-4e3d-afb9-90a573e8b1f6",
   "metadata": {},
   "source": [
    "### 항타기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12bb0e5d-4b87-4855-a0c3-35d758d921f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:59<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/공사장/18.항타기\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_piledriver = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83a81ea4-a36d-4b88-a863-123842798674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      126\n",
       "이륜차주행음      5\n",
       "차량경적        2\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_piledriver['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57c04930-61f1-4a0c-9a0c-8ae67136038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 133\n",
      "'기타소음' Count: 126\n",
      "'기타소음' Ratio: 94.74%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_piledriver = len(results_df_piledriver)  # 전체 파일 개수\n",
    "etc_noise_count_piledriver = results_df_piledriver[results_df_piledriver['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_piledriver = (etc_noise_count_piledriver / total_files_piledriver) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_piledriver}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_piledriver}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_piledriver:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e2e08f1-407b-4f1f-9d34-f28efdcbc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결과를 CSV로 저장\n",
    "# results_df_piledriver.to_csv(\"piledriver.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'piledriver.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cee9b5-d114-451d-b0fe-cb1657da67ab",
   "metadata": {},
   "source": [
    "### 콘크리트펌프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e3eea1d3-8a69-41d2-8a38-88e0ceecfbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [02:04<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/공사장/20.콘크리트펌프\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_concrete = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "866304c4-3d5b-4b54-a3aa-4e03c54401b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      88\n",
       "이륜차주행음     4\n",
       "차량사이렌      1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_concrete['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b5f548c-099a-46c4-b9ad-be302b7595ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 93\n",
      "'기타소음' Count: 88\n",
      "'기타소음' Ratio: 94.62%\n"
     ]
    }
   ],
   "source": [
    "results_df_concrete['Predicted Label'].value_counts()\n",
    "\n",
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_concrete = len(results_df_concrete)  # 전체 파일 개수\n",
    "etc_noise_count_concrete = results_df_concrete[results_df_concrete['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_concrete = (etc_noise_count_concrete / total_files_concrete) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_concrete}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_concrete}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_concrete:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9033dbc1-13d9-4589-95ae-e424ef16fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_vacuum.to_csv(\"concrete.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'concrete.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384363f2-9f7c-4b68-8465-d1be51e3036e",
   "metadata": {},
   "source": [
    "### 발전기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbb4ee05-f242-4779-9704-425d728de799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93/93 [01:59<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/공사장/20.콘크리트펌프\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_generator = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e493dde0-492d-4e04-9b41-2881625e750a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      88\n",
       "이륜차주행음     4\n",
       "차량사이렌      1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_generator['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d054d57-cdb8-46d6-a6c0-bd938dc39fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 93\n",
      "'기타소음' Count: 88\n",
      "'기타소음' Ratio: 94.62%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_generator = len(results_df_generator)  # 전체 파일 개수\n",
    "etc_noise_count_generator = results_df_generator[results_df_generator['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_generator = (etc_noise_count_generator / total_files_generator) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_generator}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_generator}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_generator:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2536f851-6592-4ad5-95f0-3c3ed13d9796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_vacuum.to_csv(\"generator.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'generator.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8990db4a-7a69-4441-945f-63c889b75abb",
   "metadata": {},
   "source": [
    "### 공구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "762d99bd-1a33-4828-a7d4-462ab7455f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [01:05<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/공구\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_tools = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4742c13-e68b-401c-ae35-ee259a5d4156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      146\n",
       "이륜차주행음     19\n",
       "차량사이렌       4\n",
       "차량주행음       2\n",
       "이륜차경적       1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_tools['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3321eb77-dc69-4955-bd3f-f88cec455a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 172\n",
      "'기타소음' Count: 146\n",
      "'기타소음' Ratio: 84.88%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_tools = len(results_df_tools)  # 전체 파일 개수\n",
    "etc_noise_count_tools = results_df_tools[results_df_tools['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_tools = (etc_noise_count_tools / total_files_tools) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_tools}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_tools}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_tools:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba81edcb-5ba8-4d9b-a6f4-2f09e505c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_vacuum.to_csv(\"tools.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'tools.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b417044",
   "metadata": {},
   "source": [
    "## 교통소음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cab28-a711-48c7-8881-0653e74cd689",
   "metadata": {},
   "source": [
    "### 차량 사이렌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a08555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [01:21<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/교통소음/2.차량사이렌\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_car_siren = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e4248b0-fd4d-4806-8ef9-2ed3e5b9ae08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량사이렌     243\n",
       "차량주행음       3\n",
       "이륜차주행음      2\n",
       "차량경적        1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_car_siren['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f9027dd-bc1e-4a62-b58e-a189d8875336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 249\n",
      "'차량사이렌' Count: 243\n",
      "'차량사이렌' Ratio: 97.59%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_car_siren = len(results_df_car_siren)  # 전체 파일 개수\n",
    "etc_noise_count_car_siren = results_df_car_siren[results_df_car_siren['Predicted Label'] == '차량사이렌'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_car_siren = (etc_noise_count_car_siren / total_files_car_siren) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_car_siren}\")\n",
    "print(f\"'차량사이렌' Count: {etc_noise_count_car_siren}\")\n",
    "print(f\"'차량사이렌' Ratio: {etc_noise_ratio_car_siren:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2a9a89f-155d-46b3-a1e6-d1be27773fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CSV로 저장\n",
    "# results_df_car_siren.to_csv(\"car_siren.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'car_siren.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb0f8f",
   "metadata": {},
   "source": [
    "### 차량 경적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b32ebd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [15:10<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/raw_data/1.Car/1.horn_of_car\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환\n",
    "results_df_car_horn = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "38c08578-d1e9-4b49-850f-0a29d6adf05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량경적      3107\n",
       "이륜차주행음      26\n",
       "이륜차경적       25\n",
       "차량주행음       19\n",
       "차량사이렌        6\n",
       "기타소음         6\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_car_horn['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02e07bba-73fb-40bd-b73c-ed7f8e5740c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 3189\n",
      "'차량경적' Count: 3107\n",
      "'차량경적' Ratio: 97.43%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_car_horn = len(results_df_car_horn)  # 전체 파일 개수\n",
    "etc_noise_count_car_horn = results_df_car_horn[results_df_car_horn['Predicted Label'] == '차량경적'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_car_horn = (etc_noise_count_car_horn / total_files_car_horn) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_car_horn}\")\n",
    "print(f\"'차량경적' Count: {etc_noise_count_car_horn}\")\n",
    "print(f\"'차량경적' Ratio: {etc_noise_ratio_car_horn:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52e58baa-df2b-44bd-a8cb-ddddba4d6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_car_horn.to_csv(\"car_horn.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'car_horn.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a5d0b-8336-4e1c-be05-0b3f3090b1e1",
   "metadata": {},
   "source": [
    "### 차량 주행음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3fb8e9ae-f896-48f4-8fb3-1b1f3872ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [01:42<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_final/교통소음/3.차량주행음\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_car_driving = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1170284e-cb3d-42dd-8456-d6431b3c428d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량주행음     215\n",
       "이륜차주행음      7\n",
       "기타소음        4\n",
       "차량경적        1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_car_driving['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9772b060-f761-4ac8-a4ac-12d087e7289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 227\n",
      "'차량주행음' Count: 215\n",
      "'차량주행음' Ratio: 94.71%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_car_driving = len(results_df_car_driving)  # 전체 파일 개수\n",
    "etc_noise_count_car_driving = results_df_car_driving[results_df_car_driving['Predicted Label'] == '차량주행음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_car_driving = (etc_noise_count_car_driving / total_files_car_driving) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_car_driving}\")\n",
    "print(f\"'차량주행음' Count: {etc_noise_count_car_driving}\")\n",
    "print(f\"'차량주행음' Ratio: {etc_noise_ratio_car_driving:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fb141210-dd00-4614-8595-d6d3101fb993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_car_driving.to_csv(\"car_driving.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'car_driving.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe461b9-ed12-4360-a937-4119060654ab",
   "metadata": {},
   "source": [
    "### 이륜차 경적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ca2add6-39d9-4f00-a34e-865b2701b450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 519/519 [02:05<00:00,  4.14it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/test_data/raw_data_test/2.Motorcycle/4.horn_of_motorcycle\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_motorcycle_horn = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fb240be-bb65-450a-a998-0b5e90ce6df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "이륜차경적     489\n",
       "차량경적       24\n",
       "이륜차주행음      4\n",
       "차량주행음       1\n",
       "기타소음        1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_motorcycle_horn['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e8c888d-ab95-4692-8561-fc98b2dbfbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 519\n",
      "'이륜차경적' Count: 489\n",
      "'이륜차경적' Ratio: 94.22%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_motorcycle_horn = len(results_df_motorcycle_horn)  # 전체 파일 개수\n",
    "etc_noise_count_motorcycle_horn = results_df_motorcycle_horn[results_df_motorcycle_horn['Predicted Label'] == '이륜차경적'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_motorcycle_horn = (etc_noise_count_motorcycle_horn / total_files_motorcycle_horn) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_motorcycle_horn}\")\n",
    "print(f\"'이륜차경적' Count: {etc_noise_count_motorcycle_horn}\")\n",
    "print(f\"'이륜차경적' Ratio: {etc_noise_ratio_motorcycle_horn:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5536ee01-3457-44be-b6d9-1c7ab7bab12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_motorcycle_horn.to_csv(\"motorcycle_horn.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'motorcycle_horn.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345929e-69f5-4375-8d2d-a74a3046f154",
   "metadata": {},
   "source": [
    "### 이륜차 주행음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "790b7294-918c-42c4-a668-bacaed714c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 498/498 [02:09<00:00,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/test_data/raw_data_test/2.Motorcycle/5.driving_sound_of_motorcycle\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_motorcycle_driving = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d1ff1c90-fc34-4e56-8cd5-05655656f45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "이륜차주행음    422\n",
       "차량주행음      58\n",
       "기타소음       14\n",
       "차량사이렌       3\n",
       "차량경적        1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_motorcycle_driving['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d24bd1cc-3c1f-4f6e-b57e-a01a4ff2998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 498\n",
      "'이륜차주행음' Count: 422\n",
      "'이륜차주행음' Ratio: 84.74%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files_motorcycle_driving = len(results_df_motorcycle_driving)  # 전체 파일 개수\n",
    "etc_noise_count_motorcycle_driving = results_df_motorcycle_driving[results_df_motorcycle_driving['Predicted Label'] == '이륜차주행음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio_motorcycle_driving = (etc_noise_count_motorcycle_driving / total_files_motorcycle_driving) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files_motorcycle_driving}\")\n",
    "print(f\"'이륜차주행음' Count: {etc_noise_count_motorcycle_driving}\")\n",
    "print(f\"'이륜차주행음' Ratio: {etc_noise_ratio_motorcycle_driving:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "acea947a-66c7-4515-abd7-00b79a3736d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CSV로 저장\n",
    "# results_df_motorcycle_driving.to_csv(\"motorcycle_driving.csv\", index=False)\n",
    "# print(\"Classification completed. Results saved to 'motorcycle_driving.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4709ae-fc2d-4640-8336-05a57e5ab619",
   "metadata": {},
   "source": [
    "# 웹 파일 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ebad2f-86b6-42aa-9144-38046d83dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 206,086\n",
      "Trainable params: 206,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Loaded Model Accuracy: 0.9667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.99      0.99      0.99      1800\n",
      "       이륜차경적       0.99      0.95      0.97       300\n",
      "      이륜차주행음       0.96      0.81      0.88       300\n",
      "        차량경적       0.94      0.98      0.96       300\n",
      "       차량사이렌       0.98      0.97      0.97       300\n",
      "       차량주행음       0.82      0.97      0.89       300\n",
      "\n",
      "    accuracy                           0.97      3300\n",
      "   macro avg       0.95      0.94      0.94      3300\n",
      "weighted avg       0.97      0.97      0.97      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = keras.models.load_model('cnn1_6classfication_category_03.h5')\n",
    "\n",
    "# 모델 구조 확인\n",
    "loaded_model.summary()\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c96e06ab-9778-4af2-8ee7-1725377ea2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_audio(audio_path):\n",
    "    try:\n",
    "        # 음원 파일 로드\n",
    "        y, sr = librosa.load(audio_path, sr=44100)\n",
    "\n",
    "        # MFCC 특징 추출\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=50)\n",
    "\n",
    "        # 추출된 MFCC 특징의 평균값을 사용 (각 MFCC 차수별로 하나의 값)\n",
    "        mfccs_processed = np.mean(mfccs, axis=1)\n",
    "\n",
    "        # CNN 입력 형태로 변환 (3D 텐서)\n",
    "        new_data = mfccs_processed.reshape(1, -1, 1)\n",
    "\n",
    "        # 예측 수행\n",
    "        predicted_label_encoded = np.argmax(loaded_model.predict(new_data), axis=-1)[0]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio file: {e}\")\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2fc3adb-8759-43d2-ab57-6a0861e80504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:03<00:00,  8.55it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/lab05/git/noise-data-platform/EB/testwav\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 결과를 DataFrame으로 변환\n",
    "results_df_motorcycle_horn = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0d31366-3811-4f52-9e44-42b45dc756f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      13\n",
       "차량주행음      5\n",
       "차량경적       4\n",
       "이륜차경적      3\n",
       "차량사이렌      2\n",
       "이륜차주행음     2\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_motorcycle_horn['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b28ed52-f80b-4aeb-8b65-0f42748ea7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['기타소음' '이륜차경적' '이륜차주행음' '차량경적' '차량사이렌' '차량주행음']\n"
     ]
    }
   ],
   "source": [
    "print(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "574a7f67-0604-4677-9127-493ed7fc8dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['기타소음' '이륜차경적' '이륜차주행음' '차량경적' '차량사이렌' '차량주행음']\n",
      "0: 기타소음\n",
      "1: 이륜차경적\n",
      "2: 이륜차주행음\n",
      "3: 차량경적\n",
      "4: 차량사이렌\n",
      "5: 차량주행음\n"
     ]
    }
   ],
   "source": [
    "# 클래스 이름 확인\n",
    "print(\"Class Names:\", class_names)\n",
    "\n",
    "for i, class_name in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {class_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b0a0f4-8797-41ef-8dc0-626120c4b2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'testwav_cnn1_category03.csv'\n"
     ]
    }
   ],
   "source": [
    "# CSV로 저장\n",
    "results_df_motorcycle_horn.to_csv(\"testwav_cnn1_category03.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'testwav_cnn1_category03.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232f1174-563c-473f-8710-bf31e9f4df89",
   "metadata": {},
   "source": [
    "# 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b70524bf-2276-4d83-9c90-d1e01805f89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 50, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 22, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 207,366\n",
      "Trainable params: 206,726\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Loaded Model Accuracy: 0.9537\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.97      0.93      0.95       373\n",
      "       이륜차경적       0.98      0.95      0.97       912\n",
      "      이륜차주행음       0.95      0.97      0.96       947\n",
      "        차량경적       0.93      0.95      0.94       638\n",
      "       차량사이렌       0.98      0.96      0.97       398\n",
      "       차량주행음       0.89      0.93      0.91       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.95      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = keras.models.load_model('cnn2_6classfication_original.h5')\n",
    "\n",
    "# 모델 구조 확인\n",
    "loaded_model.summary()\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc7e807-0b1a-4072-8c07-5365f4c3429f",
   "metadata": {},
   "source": [
    "## 기타 소음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "744af1c7-9283-496a-b879-4b625209d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고양이 Total Files: 274\n",
      "'기타소음' Count: 271\n",
      "'기타소음' Ratio: 98.91%\n",
      "******************************\n",
      "강아지 Total Files: 217\n",
      "'기타소음' Count: 210\n",
      "'기타소음' Ratio: 96.77%\n",
      "******************************\n",
      "향타기 Total Files: 133\n",
      "'기타소음' Count: 126\n",
      "'기타소음' Ratio: 94.74%\n",
      "******************************\n",
      "콘크리트펌프 Total Files: 93\n",
      "'기타소음' Count: 88\n",
      "'기타소음' Ratio: 94.62%\n",
      "******************************\n",
      "발전기 Total Files: 93\n",
      "'기타소음' Count: 88\n",
      "'기타소음' Ratio: 94.62%\n",
      "******************************\n",
      "공구 Total Files: 172\n",
      "'기타소음' Count: 146\n",
      "'기타소음' Ratio: 84.88%\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(f\"고양이 Total Files: {total_files_cat}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_cat}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_cat:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"강아지 Total Files: {total_files_dog}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_dog}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_dog:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"향타기 Total Files: {total_files_piledriver}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_piledriver}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_piledriver:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"콘크리트펌프 Total Files: {total_files_concrete}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_concrete}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_concrete:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"발전기 Total Files: {total_files_generator}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_generator}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_generator:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"공구 Total Files: {total_files_tools}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count_tools}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio_tools:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43ecca-af1b-4488-95e6-ce25aaf6834a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e809131b-d3a5-4781-9222-de1d218ae9c9",
   "metadata": {},
   "source": [
    "## 교통 소음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f14e14da-8122-4487-8409-c57ccc017dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차량사이렌 Total Files: 249\n",
      "'차량사이렌' Count: 243\n",
      "'차량사이렌' Ratio: 97.59%\n",
      "******************************\n",
      "차량경적 Total Files: 3189\n",
      "'차량경적' Count: 3107\n",
      "'차량경적' Ratio: 97.43%\n",
      "******************************\n",
      "차량주행음 Total Files: 227\n",
      "'차량주행음' Count: 215\n",
      "'차량주행음' Ratio: 94.71%\n",
      "******************************\n",
      "이륜차경적 Total Files: 519\n",
      "'이륜차경적' Count: 489\n",
      "'이륜차경적' Ratio: 94.22%\n",
      "******************************\n",
      "이륜차주행음 Total Files: 498\n",
      "'이륜차주행음' Count: 422\n",
      "'이륜차주행음' Ratio: 84.74%\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "print(f\"차량사이렌 Total Files: {total_files_car_siren}\")\n",
    "print(f\"'차량사이렌' Count: {etc_noise_count_car_siren}\")\n",
    "print(f\"'차량사이렌' Ratio: {etc_noise_ratio_car_siren:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"차량경적 Total Files: {total_files_car_horn}\")\n",
    "print(f\"'차량경적' Count: {etc_noise_count_car_horn}\")\n",
    "print(f\"'차량경적' Ratio: {etc_noise_ratio_car_horn:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"차량주행음 Total Files: {total_files_car_driving}\")\n",
    "print(f\"'차량주행음' Count: {etc_noise_count_car_driving}\")\n",
    "print(f\"'차량주행음' Ratio: {etc_noise_ratio_car_driving:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"이륜차경적 Total Files: {total_files_motorcycle_horn}\")\n",
    "print(f\"'이륜차경적' Count: {etc_noise_count_motorcycle_horn}\")\n",
    "print(f\"'이륜차경적' Ratio: {etc_noise_ratio_motorcycle_horn:.2f}%\")\n",
    "print('*'*30)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"이륜차주행음 Total Files: {total_files_motorcycle_driving}\")\n",
    "print(f\"'이륜차주행음' Count: {etc_noise_count_motorcycle_driving}\")\n",
    "print(f\"'이륜차주행음' Ratio: {etc_noise_ratio_motorcycle_driving:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad50f04-f6b1-4d2c-85e6-3f3f6873a629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdc22d-6ba4-406f-b247-2c08df2915ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
