{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c619aa16-8717-46d3-be1d-44aa38bf72a1",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344916b7-21de-4e02-92f3-4203de25ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import config \n",
    "from config import DB_CONFIG\n",
    "import pymysql  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad936e2-f844-4fdc-99ae-9876b0157418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL 연결\n",
    "conn = pymysql.connect(\n",
    "    host=DB_CONFIG['host'],\n",
    "    user=DB_CONFIG['user'],\n",
    "    password=DB_CONFIG['password'],\n",
    "    database=DB_CONFIG['database'],\n",
    "    port=DB_CONFIG['port']\n",
    ")\n",
    "\n",
    "car_siren = f\"SELECT * FROM merge50_car_siren\"\n",
    "car_horn = f\"SELECT * FROM merge50_car_horn\"\n",
    "car_driving = f'SELECT * FROM merge50_car_driving'\n",
    "motorcycle_horn  = f'SELECT * FROM merge50_motorcycle_horn'\n",
    "motorcycle_driving  = f'SELECT * FROM merge50_motorcycle_driving'\n",
    "\n",
    "car_siren_df =  pd.read_sql(car_siren, conn)\n",
    "car_horn_df = pd.read_sql(car_horn, conn) \n",
    "car_driving_df = pd.read_sql(car_driving, conn) \n",
    "motorcycle_horn_df= pd.read_sql(motorcycle_horn, conn) \n",
    "motorcycle_driving_df = pd.read_sql(motorcycle_driving, conn) \n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8735bd5-74f9-439d-9f27-ede4732854c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car_siren 데이터 개수: 1990\n",
      "car_horn 데이터 개수: 3189\n",
      "car_driving 데이터 개수: 1682\n",
      "motorcycle_horn 데이터 개수: 4560\n",
      "motorcycle_driving 데이터 개수: 4735\n"
     ]
    }
   ],
   "source": [
    "print(f'car_siren 데이터 개수: {car_siren_df.shape[0]}')\n",
    "print(f'car_horn 데이터 개수: {car_horn_df.shape[0]}')\n",
    "print(f'car_driving 데이터 개수: {car_driving_df.shape[0]}')\n",
    "print(f'motorcycle_horn 데이터 개수: {motorcycle_horn_df.shape[0]}')\n",
    "print(f'motorcycle_driving 데이터 개수: {motorcycle_driving_df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf70ad4-b037-44fc-ac4b-7ea51324fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1990 entries, 0 to 1989\n",
      "Data columns (total 82 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   fileName       1990 non-null   object \n",
      " 1   labelName      1990 non-null   object \n",
      " 2   area_start     1990 non-null   float64\n",
      " 3   area_end       1990 non-null   float64\n",
      " 4   category_01    1990 non-null   object \n",
      " 5   category_02    1990 non-null   object \n",
      " 6   category_03    1990 non-null   object \n",
      " 7   decibel        1990 non-null   int64  \n",
      " 8   soundQuality   1990 non-null   object \n",
      " 9   subCategory    1990 non-null   object \n",
      " 10  bitRate        1990 non-null   object \n",
      " 11  duration       1990 non-null   float64\n",
      " 12  fileFormat     1990 non-null   object \n",
      " 13  fileSize       1990 non-null   int64  \n",
      " 14  recodingType   1990 non-null   object \n",
      " 15  sampleRate     1990 non-null   object \n",
      " 16  acqDevice      1990 non-null   object \n",
      " 17  acqMethod      1990 non-null   object \n",
      " 18  acqType        1990 non-null   object \n",
      " 19  areaUse        1990 non-null   object \n",
      " 20  dayNight       1990 non-null   object \n",
      " 21  direction      1990 non-null   object \n",
      " 22  distance       1990 non-null   object \n",
      " 23  district       1990 non-null   object \n",
      " 24  latitude       1990 non-null   float64\n",
      " 25  longitude      1990 non-null   float64\n",
      " 26  micClass       1990 non-null   object \n",
      " 27  obstacle       1990 non-null   object \n",
      " 28  place          1990 non-null   object \n",
      " 29  recordingTime  1990 non-null   object \n",
      " 30  urban          1990 non-null   object \n",
      " 31  weather        1990 non-null   object \n",
      " 32  mfcc_1         1990 non-null   float64\n",
      " 33  mfcc_2         1990 non-null   float64\n",
      " 34  mfcc_3         1990 non-null   float64\n",
      " 35  mfcc_4         1990 non-null   float64\n",
      " 36  mfcc_5         1990 non-null   float64\n",
      " 37  mfcc_6         1990 non-null   float64\n",
      " 38  mfcc_7         1990 non-null   float64\n",
      " 39  mfcc_8         1990 non-null   float64\n",
      " 40  mfcc_9         1990 non-null   float64\n",
      " 41  mfcc_10        1990 non-null   float64\n",
      " 42  mfcc_11        1990 non-null   float64\n",
      " 43  mfcc_12        1990 non-null   float64\n",
      " 44  mfcc_13        1990 non-null   float64\n",
      " 45  mfcc_14        1990 non-null   float64\n",
      " 46  mfcc_15        1990 non-null   float64\n",
      " 47  mfcc_16        1990 non-null   float64\n",
      " 48  mfcc_17        1990 non-null   float64\n",
      " 49  mfcc_18        1990 non-null   float64\n",
      " 50  mfcc_19        1990 non-null   float64\n",
      " 51  mfcc_20        1990 non-null   float64\n",
      " 52  mfcc_21        1990 non-null   float64\n",
      " 53  mfcc_22        1990 non-null   float64\n",
      " 54  mfcc_23        1990 non-null   float64\n",
      " 55  mfcc_24        1990 non-null   float64\n",
      " 56  mfcc_25        1990 non-null   float64\n",
      " 57  mfcc_26        1990 non-null   float64\n",
      " 58  mfcc_27        1990 non-null   float64\n",
      " 59  mfcc_28        1990 non-null   float64\n",
      " 60  mfcc_29        1990 non-null   float64\n",
      " 61  mfcc_30        1990 non-null   float64\n",
      " 62  mfcc_31        1990 non-null   float64\n",
      " 63  mfcc_32        1990 non-null   float64\n",
      " 64  mfcc_33        1990 non-null   float64\n",
      " 65  mfcc_34        1990 non-null   float64\n",
      " 66  mfcc_35        1990 non-null   float64\n",
      " 67  mfcc_36        1990 non-null   float64\n",
      " 68  mfcc_37        1990 non-null   float64\n",
      " 69  mfcc_38        1990 non-null   float64\n",
      " 70  mfcc_39        1990 non-null   float64\n",
      " 71  mfcc_40        1990 non-null   float64\n",
      " 72  mfcc_41        1990 non-null   float64\n",
      " 73  mfcc_42        1990 non-null   float64\n",
      " 74  mfcc_43        1990 non-null   float64\n",
      " 75  mfcc_44        1990 non-null   float64\n",
      " 76  mfcc_45        1990 non-null   float64\n",
      " 77  mfcc_46        1990 non-null   float64\n",
      " 78  mfcc_47        1990 non-null   float64\n",
      " 79  mfcc_48        1990 non-null   float64\n",
      " 80  mfcc_49        1990 non-null   float64\n",
      " 81  mfcc_50        1990 non-null   float64\n",
      "dtypes: float64(55), int64(2), object(25)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "car_siren_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7712a8ba-db33-4b7d-a24c-d827fc063681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_41</th>\n",
       "      <th>mfcc_42</th>\n",
       "      <th>mfcc_43</th>\n",
       "      <th>mfcc_44</th>\n",
       "      <th>mfcc_45</th>\n",
       "      <th>mfcc_46</th>\n",
       "      <th>mfcc_47</th>\n",
       "      <th>mfcc_48</th>\n",
       "      <th>mfcc_49</th>\n",
       "      <th>mfcc_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-391.00430</td>\n",
       "      <td>107.641975</td>\n",
       "      <td>64.204640</td>\n",
       "      <td>33.718952</td>\n",
       "      <td>20.630340</td>\n",
       "      <td>13.337987</td>\n",
       "      <td>9.100019</td>\n",
       "      <td>8.873220</td>\n",
       "      <td>9.340549</td>\n",
       "      <td>8.287990</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.194056</td>\n",
       "      <td>-0.757743</td>\n",
       "      <td>-2.858810</td>\n",
       "      <td>-5.101422</td>\n",
       "      <td>-0.198150</td>\n",
       "      <td>7.001447</td>\n",
       "      <td>6.203896</td>\n",
       "      <td>-2.862313</td>\n",
       "      <td>-10.336964</td>\n",
       "      <td>-8.593492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-233.66284</td>\n",
       "      <td>87.917620</td>\n",
       "      <td>45.434906</td>\n",
       "      <td>19.435001</td>\n",
       "      <td>9.098841</td>\n",
       "      <td>32.400368</td>\n",
       "      <td>5.817845</td>\n",
       "      <td>9.204194</td>\n",
       "      <td>14.611247</td>\n",
       "      <td>20.294502</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.923782</td>\n",
       "      <td>8.347244</td>\n",
       "      <td>-2.440833</td>\n",
       "      <td>-17.408949</td>\n",
       "      <td>-5.891588</td>\n",
       "      <td>22.778133</td>\n",
       "      <td>21.374588</td>\n",
       "      <td>-19.310514</td>\n",
       "      <td>-26.457247</td>\n",
       "      <td>4.794274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-318.16153</td>\n",
       "      <td>126.123180</td>\n",
       "      <td>43.729805</td>\n",
       "      <td>-11.429483</td>\n",
       "      <td>-5.223235</td>\n",
       "      <td>13.667998</td>\n",
       "      <td>0.934844</td>\n",
       "      <td>10.497743</td>\n",
       "      <td>2.401143</td>\n",
       "      <td>22.281258</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.953082</td>\n",
       "      <td>1.538178</td>\n",
       "      <td>-0.032047</td>\n",
       "      <td>-10.759938</td>\n",
       "      <td>-10.296665</td>\n",
       "      <td>14.938017</td>\n",
       "      <td>19.099138</td>\n",
       "      <td>-5.256958</td>\n",
       "      <td>-27.792421</td>\n",
       "      <td>-7.377015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-385.20926</td>\n",
       "      <td>140.265410</td>\n",
       "      <td>57.263832</td>\n",
       "      <td>-7.932145</td>\n",
       "      <td>-3.877982</td>\n",
       "      <td>14.155136</td>\n",
       "      <td>6.298158</td>\n",
       "      <td>11.397833</td>\n",
       "      <td>2.566783</td>\n",
       "      <td>15.076704</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.018665</td>\n",
       "      <td>2.996135</td>\n",
       "      <td>-0.142866</td>\n",
       "      <td>-8.995171</td>\n",
       "      <td>-4.227169</td>\n",
       "      <td>8.116351</td>\n",
       "      <td>11.163322</td>\n",
       "      <td>-4.992955</td>\n",
       "      <td>-16.359087</td>\n",
       "      <td>-5.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-382.12450</td>\n",
       "      <td>150.004900</td>\n",
       "      <td>61.439040</td>\n",
       "      <td>-17.890905</td>\n",
       "      <td>-7.740589</td>\n",
       "      <td>15.947204</td>\n",
       "      <td>3.806582</td>\n",
       "      <td>7.909450</td>\n",
       "      <td>2.633213</td>\n",
       "      <td>14.426663</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.330876</td>\n",
       "      <td>2.107300</td>\n",
       "      <td>1.768516</td>\n",
       "      <td>-10.489394</td>\n",
       "      <td>-4.815802</td>\n",
       "      <td>9.592706</td>\n",
       "      <td>12.866017</td>\n",
       "      <td>-3.469832</td>\n",
       "      <td>-20.286922</td>\n",
       "      <td>-6.563427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>-99.19382</td>\n",
       "      <td>119.270660</td>\n",
       "      <td>-76.342830</td>\n",
       "      <td>14.679804</td>\n",
       "      <td>-26.403290</td>\n",
       "      <td>5.220899</td>\n",
       "      <td>-15.944427</td>\n",
       "      <td>-0.425459</td>\n",
       "      <td>-14.378425</td>\n",
       "      <td>-2.452169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.322109</td>\n",
       "      <td>-1.603073</td>\n",
       "      <td>-0.969422</td>\n",
       "      <td>-0.030491</td>\n",
       "      <td>-3.283236</td>\n",
       "      <td>-4.058084</td>\n",
       "      <td>-2.597992</td>\n",
       "      <td>-0.028827</td>\n",
       "      <td>1.399276</td>\n",
       "      <td>-4.661576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>-292.45557</td>\n",
       "      <td>203.069000</td>\n",
       "      <td>-53.426810</td>\n",
       "      <td>37.105576</td>\n",
       "      <td>6.516268</td>\n",
       "      <td>10.316400</td>\n",
       "      <td>11.667080</td>\n",
       "      <td>1.168588</td>\n",
       "      <td>17.977980</td>\n",
       "      <td>5.434537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412159</td>\n",
       "      <td>-0.795219</td>\n",
       "      <td>-1.426503</td>\n",
       "      <td>-3.167590</td>\n",
       "      <td>-2.035457</td>\n",
       "      <td>0.571453</td>\n",
       "      <td>4.668703</td>\n",
       "      <td>3.238892</td>\n",
       "      <td>-5.142219</td>\n",
       "      <td>-4.995093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>-198.79451</td>\n",
       "      <td>201.686460</td>\n",
       "      <td>-87.792480</td>\n",
       "      <td>-11.408583</td>\n",
       "      <td>-14.657739</td>\n",
       "      <td>-5.088332</td>\n",
       "      <td>-0.388612</td>\n",
       "      <td>-13.570362</td>\n",
       "      <td>6.362044</td>\n",
       "      <td>-11.089597</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.205375</td>\n",
       "      <td>0.633744</td>\n",
       "      <td>2.143693</td>\n",
       "      <td>-4.530044</td>\n",
       "      <td>-7.654323</td>\n",
       "      <td>3.844430</td>\n",
       "      <td>9.282047</td>\n",
       "      <td>2.180258</td>\n",
       "      <td>-6.707889</td>\n",
       "      <td>-3.188458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>-247.43971</td>\n",
       "      <td>186.716000</td>\n",
       "      <td>-45.675808</td>\n",
       "      <td>47.491760</td>\n",
       "      <td>18.612213</td>\n",
       "      <td>16.028240</td>\n",
       "      <td>8.016017</td>\n",
       "      <td>3.121070</td>\n",
       "      <td>13.013415</td>\n",
       "      <td>4.386095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659112</td>\n",
       "      <td>-2.346271</td>\n",
       "      <td>-1.647404</td>\n",
       "      <td>-0.503469</td>\n",
       "      <td>0.055166</td>\n",
       "      <td>-0.353136</td>\n",
       "      <td>-0.114590</td>\n",
       "      <td>1.304396</td>\n",
       "      <td>0.613524</td>\n",
       "      <td>-0.592904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>-295.30887</td>\n",
       "      <td>224.132390</td>\n",
       "      <td>-42.393883</td>\n",
       "      <td>30.421978</td>\n",
       "      <td>18.980920</td>\n",
       "      <td>9.521865</td>\n",
       "      <td>16.274446</td>\n",
       "      <td>0.520351</td>\n",
       "      <td>13.609183</td>\n",
       "      <td>2.586846</td>\n",
       "      <td>...</td>\n",
       "      <td>4.073492</td>\n",
       "      <td>-0.281517</td>\n",
       "      <td>1.813115</td>\n",
       "      <td>1.477441</td>\n",
       "      <td>-1.411676</td>\n",
       "      <td>-2.991270</td>\n",
       "      <td>-2.364653</td>\n",
       "      <td>2.412057</td>\n",
       "      <td>2.298984</td>\n",
       "      <td>-1.866335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3189 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         mfcc_1      mfcc_2     mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0    -391.00430  107.641975  64.204640  33.718952  20.630340  13.337987   \n",
       "1    -233.66284   87.917620  45.434906  19.435001   9.098841  32.400368   \n",
       "2    -318.16153  126.123180  43.729805 -11.429483  -5.223235  13.667998   \n",
       "3    -385.20926  140.265410  57.263832  -7.932145  -3.877982  14.155136   \n",
       "4    -382.12450  150.004900  61.439040 -17.890905  -7.740589  15.947204   \n",
       "...         ...         ...        ...        ...        ...        ...   \n",
       "3184  -99.19382  119.270660 -76.342830  14.679804 -26.403290   5.220899   \n",
       "3185 -292.45557  203.069000 -53.426810  37.105576   6.516268  10.316400   \n",
       "3186 -198.79451  201.686460 -87.792480 -11.408583 -14.657739  -5.088332   \n",
       "3187 -247.43971  186.716000 -45.675808  47.491760  18.612213  16.028240   \n",
       "3188 -295.30887  224.132390 -42.393883  30.421978  18.980920   9.521865   \n",
       "\n",
       "         mfcc_7     mfcc_8     mfcc_9    mfcc_10  ...   mfcc_41   mfcc_42  \\\n",
       "0      9.100019   8.873220   9.340549   8.287990  ... -1.194056 -0.757743   \n",
       "1      5.817845   9.204194  14.611247  20.294502  ... -7.923782  8.347244   \n",
       "2      0.934844  10.497743   2.401143  22.281258  ... -5.953082  1.538178   \n",
       "3      6.298158  11.397833   2.566783  15.076704  ... -5.018665  2.996135   \n",
       "4      3.806582   7.909450   2.633213  14.426663  ... -5.330876  2.107300   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "3184 -15.944427  -0.425459 -14.378425  -2.452169  ...  1.322109 -1.603073   \n",
       "3185  11.667080   1.168588  17.977980   5.434537  ...  0.412159 -0.795219   \n",
       "3186  -0.388612 -13.570362   6.362044 -11.089597  ... -1.205375  0.633744   \n",
       "3187   8.016017   3.121070  13.013415   4.386095  ...  0.659112 -2.346271   \n",
       "3188  16.274446   0.520351  13.609183   2.586846  ...  4.073492 -0.281517   \n",
       "\n",
       "       mfcc_43    mfcc_44    mfcc_45    mfcc_46    mfcc_47    mfcc_48  \\\n",
       "0    -2.858810  -5.101422  -0.198150   7.001447   6.203896  -2.862313   \n",
       "1    -2.440833 -17.408949  -5.891588  22.778133  21.374588 -19.310514   \n",
       "2    -0.032047 -10.759938 -10.296665  14.938017  19.099138  -5.256958   \n",
       "3    -0.142866  -8.995171  -4.227169   8.116351  11.163322  -4.992955   \n",
       "4     1.768516 -10.489394  -4.815802   9.592706  12.866017  -3.469832   \n",
       "...        ...        ...        ...        ...        ...        ...   \n",
       "3184 -0.969422  -0.030491  -3.283236  -4.058084  -2.597992  -0.028827   \n",
       "3185 -1.426503  -3.167590  -2.035457   0.571453   4.668703   3.238892   \n",
       "3186  2.143693  -4.530044  -7.654323   3.844430   9.282047   2.180258   \n",
       "3187 -1.647404  -0.503469   0.055166  -0.353136  -0.114590   1.304396   \n",
       "3188  1.813115   1.477441  -1.411676  -2.991270  -2.364653   2.412057   \n",
       "\n",
       "        mfcc_49   mfcc_50  \n",
       "0    -10.336964 -8.593492  \n",
       "1    -26.457247  4.794274  \n",
       "2    -27.792421 -7.377015  \n",
       "3    -16.359087 -5.441961  \n",
       "4    -20.286922 -6.563427  \n",
       "...         ...       ...  \n",
       "3184   1.399276 -4.661576  \n",
       "3185  -5.142219 -4.995093  \n",
       "3186  -6.707889 -3.188458  \n",
       "3187   0.613524 -0.592904  \n",
       "3188   2.298984 -1.866335  \n",
       "\n",
       "[3189 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_horn_df.iloc[ : ,-50:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96996849-7c10-47fb-b4c8-947e65402661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_combined 행 개수: 16156\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileName</th>\n",
       "      <th>labelName</th>\n",
       "      <th>area_start</th>\n",
       "      <th>area_end</th>\n",
       "      <th>category_01</th>\n",
       "      <th>category_02</th>\n",
       "      <th>category_03</th>\n",
       "      <th>decibel</th>\n",
       "      <th>soundQuality</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc_41</th>\n",
       "      <th>mfcc_42</th>\n",
       "      <th>mfcc_43</th>\n",
       "      <th>mfcc_44</th>\n",
       "      <th>mfcc_45</th>\n",
       "      <th>mfcc_46</th>\n",
       "      <th>mfcc_47</th>\n",
       "      <th>mfcc_48</th>\n",
       "      <th>mfcc_49</th>\n",
       "      <th>mfcc_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.car_horn_87900_1.wav</td>\n",
       "      <td>1.car_horn_87900_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.719</td>\n",
       "      <td>교통소음</td>\n",
       "      <td>자동차</td>\n",
       "      <td>차량경적</td>\n",
       "      <td>116</td>\n",
       "      <td>정상</td>\n",
       "      <td>소형차경적</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.194056</td>\n",
       "      <td>-0.757743</td>\n",
       "      <td>-2.858810</td>\n",
       "      <td>-5.101422</td>\n",
       "      <td>-0.198150</td>\n",
       "      <td>7.001447</td>\n",
       "      <td>6.203896</td>\n",
       "      <td>-2.862313</td>\n",
       "      <td>-10.336964</td>\n",
       "      <td>-8.593492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.car_horn_87964_1.wav</td>\n",
       "      <td>1.car_horn_87964_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.747</td>\n",
       "      <td>교통소음</td>\n",
       "      <td>자동차</td>\n",
       "      <td>차량경적</td>\n",
       "      <td>102</td>\n",
       "      <td>정상</td>\n",
       "      <td>소형차경적</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.923782</td>\n",
       "      <td>8.347244</td>\n",
       "      <td>-2.440833</td>\n",
       "      <td>-17.408949</td>\n",
       "      <td>-5.891588</td>\n",
       "      <td>22.778133</td>\n",
       "      <td>21.374588</td>\n",
       "      <td>-19.310514</td>\n",
       "      <td>-26.457247</td>\n",
       "      <td>4.794274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.car_horn_87987_1.wav</td>\n",
       "      <td>1.car_horn_87987_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.217</td>\n",
       "      <td>교통소음</td>\n",
       "      <td>자동차</td>\n",
       "      <td>차량경적</td>\n",
       "      <td>112</td>\n",
       "      <td>정상</td>\n",
       "      <td>소형차경적</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.953082</td>\n",
       "      <td>1.538178</td>\n",
       "      <td>-0.032047</td>\n",
       "      <td>-10.759938</td>\n",
       "      <td>-10.296665</td>\n",
       "      <td>14.938017</td>\n",
       "      <td>19.099138</td>\n",
       "      <td>-5.256958</td>\n",
       "      <td>-27.792421</td>\n",
       "      <td>-7.377015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.car_horn_88000_1.wav</td>\n",
       "      <td>1.car_horn_88000_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.389</td>\n",
       "      <td>교통소음</td>\n",
       "      <td>자동차</td>\n",
       "      <td>차량경적</td>\n",
       "      <td>112</td>\n",
       "      <td>정상</td>\n",
       "      <td>소형차경적</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.018665</td>\n",
       "      <td>2.996135</td>\n",
       "      <td>-0.142866</td>\n",
       "      <td>-8.995171</td>\n",
       "      <td>-4.227169</td>\n",
       "      <td>8.116351</td>\n",
       "      <td>11.163322</td>\n",
       "      <td>-4.992955</td>\n",
       "      <td>-16.359087</td>\n",
       "      <td>-5.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.car_horn_88001_1.wav</td>\n",
       "      <td>1.car_horn_88001_1.wav</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.207</td>\n",
       "      <td>교통소음</td>\n",
       "      <td>자동차</td>\n",
       "      <td>차량경적</td>\n",
       "      <td>122</td>\n",
       "      <td>정상</td>\n",
       "      <td>소형차경적</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.330876</td>\n",
       "      <td>2.107300</td>\n",
       "      <td>1.768516</td>\n",
       "      <td>-10.489394</td>\n",
       "      <td>-4.815802</td>\n",
       "      <td>9.592706</td>\n",
       "      <td>12.866017</td>\n",
       "      <td>-3.469832</td>\n",
       "      <td>-20.286922</td>\n",
       "      <td>-6.563427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 fileName               labelName  area_start  area_end  \\\n",
       "0  1.car_horn_87900_1.wav  1.car_horn_87900_1.wav         2.0    58.719   \n",
       "1  1.car_horn_87964_1.wav  1.car_horn_87964_1.wav         2.0    59.747   \n",
       "2  1.car_horn_87987_1.wav  1.car_horn_87987_1.wav         2.0    59.217   \n",
       "3  1.car_horn_88000_1.wav  1.car_horn_88000_1.wav         2.0    57.389   \n",
       "4  1.car_horn_88001_1.wav  1.car_horn_88001_1.wav         2.0    58.207   \n",
       "\n",
       "  category_01 category_02 category_03  decibel soundQuality subCategory  ...  \\\n",
       "0        교통소음         자동차        차량경적      116           정상       소형차경적  ...   \n",
       "1        교통소음         자동차        차량경적      102           정상       소형차경적  ...   \n",
       "2        교통소음         자동차        차량경적      112           정상       소형차경적  ...   \n",
       "3        교통소음         자동차        차량경적      112           정상       소형차경적  ...   \n",
       "4        교통소음         자동차        차량경적      122           정상       소형차경적  ...   \n",
       "\n",
       "    mfcc_41   mfcc_42   mfcc_43    mfcc_44    mfcc_45    mfcc_46    mfcc_47  \\\n",
       "0 -1.194056 -0.757743 -2.858810  -5.101422  -0.198150   7.001447   6.203896   \n",
       "1 -7.923782  8.347244 -2.440833 -17.408949  -5.891588  22.778133  21.374588   \n",
       "2 -5.953082  1.538178 -0.032047 -10.759938 -10.296665  14.938017  19.099138   \n",
       "3 -5.018665  2.996135 -0.142866  -8.995171  -4.227169   8.116351  11.163322   \n",
       "4 -5.330876  2.107300  1.768516 -10.489394  -4.815802   9.592706  12.866017   \n",
       "\n",
       "     mfcc_48    mfcc_49   mfcc_50  \n",
       "0  -2.862313 -10.336964 -8.593492  \n",
       "1 -19.310514 -26.457247  4.794274  \n",
       "2  -5.256958 -27.792421 -7.377015  \n",
       "3  -4.992955 -16.359087 -5.441961  \n",
       "4  -3.469832 -20.286922 -6.563427  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터프레임 병합 \n",
    "df_combined = pd.concat([car_horn_df, car_siren_df,car_driving_df,motorcycle_horn_df,motorcycle_driving_df], ignore_index=True)\n",
    "\n",
    "print(f'df_combined 행 개수: {len(df_combined)}') \n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930cb64-1813-49aa-8522-f91662570811",
   "metadata": {},
   "source": [
    "# lightGBM + ODD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860f8fa4-0944-4f3c-a5b5-11b9c71fb060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "LightGBM 정확도: 0.9449\n",
      "\n",
      "Confusion Matrix:\n",
      "        이륜차경적  이륜차주행음  차량경적  차량사이렌  차량주행음\n",
      "이륜차경적     902       2    44      1      0\n",
      "이륜차주행음      0     885     3      1     26\n",
      "차량경적       24      10   582      1      4\n",
      "차량사이렌       0      11     3    401      7\n",
      "차량주행음       0      40     0      1    284\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       이륜차경적       0.97      0.95      0.96       949\n",
      "      이륜차주행음       0.93      0.97      0.95       915\n",
      "        차량경적       0.92      0.94      0.93       621\n",
      "       차량사이렌       0.99      0.95      0.97       422\n",
      "       차량주행음       0.88      0.87      0.88       325\n",
      "\n",
      "    accuracy                           0.94      3232\n",
      "   macro avg       0.94      0.94      0.94      3232\n",
      "weighted avg       0.95      0.94      0.95      3232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# 레이블(label)과 피처(features) 분리\n",
    "X = df_combined.iloc[:, -50:]  # 마지막 13개 컬럼을 특성(MFCC)으로 사용\n",
    "y = df_combined['category_03'].astype('category').cat.codes  # 범주형 데이터를 숫자로 변환\n",
    "\n",
    "# 범주형 데이터(레이블) 숫자로 변환\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "# 클래스 레이블 매핑\n",
    "class_labels = df_combined['category_03'].astype('category').cat.categories\n",
    "\n",
    "# 데이터셋 분할 (train: 80%, test: 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(set(y))\n",
    "print(num_classes)\n",
    "\n",
    "# LightGBM 모델 정의 및 학습\n",
    "model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평가 결과 출력\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"LightGBM 정확도: {acc:.4f}\")\n",
    "\n",
    "# 혼동 행렬 및 분류 보고서 출력\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), index=class_labels, columns=class_labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_labels.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab4ae78b-3519-420b-84be-85168b925e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 성공적으로 저장되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# 모델 학습\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 저장 (Booster 객체 사용)\n",
    "model.booster_.save_model('lgbm_model.txt')\n",
    "\n",
    "print(\"모델이 성공적으로 저장되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0f392-c2f4-4451-9450-40fe226025b4",
   "metadata": {},
   "source": [
    "# df_etc 기타 소음 (열차, 비행기) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f06e5e2-5d44-44c2-b2eb-aef3d3dd78eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/ubuntu/data/etc_noise_data_test\"\n",
    "\n",
    "# 기존 데이터프레임이 존재하는지 확인\n",
    "try:\n",
    "    df_combined\n",
    "except NameError:\n",
    "    df_combined = pd.DataFrame()  # 없으면 빈 데이터프레임 생성\n",
    "\n",
    "json_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "            annotation = annotations[0] if annotations and isinstance(annotations, list) else {}\n",
    "\n",
    "            # JSON 파일명에서 확장자 제거\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "\n",
    "            json_data.append({\n",
    "                \"baseName\": base_name,  # 확장자 없는 파일명 저장\n",
    "                \"fileName\": data[\"audio\"][\"fileName\"],\n",
    "                \"labelName\": annotation.get(\"labelName\", None),\n",
    "                \"area_start\": annotation.get(\"area\", {}).get(\"start\", None),\n",
    "                \"area_end\": annotation.get(\"area\", {}).get(\"end\", None),\n",
    "                \"category_01\": annotation.get(\"categories\", {}).get(\"category_01\", None),\n",
    "                \"category_02\": annotation.get(\"categories\", {}).get(\"category_02\", None),\n",
    "                \"category_03\": annotation.get(\"categories\", {}).get(\"category_03\", None),\n",
    "                \"decibel\": annotation.get(\"decibel\", None),\n",
    "                \"soundQuality\": annotation.get(\"soundQuality\", None),\n",
    "                \"subCategory\": annotation.get(\"subCategory\", None),\n",
    "            })\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "# WAV 파일에서 MFCC 추출하는 함수\n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=50):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # MFCC 평균값 반환\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {file_path} - {e}\")\n",
    "        return [None] * n_mfcc  # 오류 발생 시 None 리스트 반환\n",
    "\n",
    "wav_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        base_name = \"_\".join(file.split(\"_\")[:-1])  # \"_1.wav\" 부분 제거하고 기본 파일명 추출\n",
    "        mfcc_features = extract_mfcc(file_path)\n",
    "\n",
    "        wav_data.append({\n",
    "            \"baseName\": base_name,  # JSON과 매칭할 기본 파일명 저장\n",
    "            **{f\"mfcc_{i+1}\": mfcc for i, mfcc in enumerate(mfcc_features)}\n",
    "        })\n",
    "\n",
    "df_wav = pd.DataFrame(wav_data)\n",
    "\n",
    "# # JSON 데이터와 WAV 데이터 병합 (baseName 기준)\n",
    "df_etc = pd.merge(df_json, df_wav, on=\"baseName\", how=\"left\").drop(columns=[\"baseName\"])\n",
    "\n",
    "# # 기존 데이터프레임 df_combined에 추가\n",
    "df_combined2 = pd.concat([df_combined, df_etc], ignore_index=True)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c0155a-24f7-4b31-a45a-6a8260e7850a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 테스트 데이터 예측 결과: [ 2 -1  1 ...  4  0  3]\n",
      "✅ OOD (기타 소음) 예측 결과 (Softmax 기반 필터링): [ 1  1  1  1  1  1  1 -1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "# 📌 4️⃣ OOD 데이터 로드 & 전처리 (MFCC 특징 사용)\n",
    "ood_X_test = df_etc.iloc[:, -50:]  # OOD 데이터의 MFCC 13개 컬럼 사용\n",
    "\n",
    "# 📌 5️⃣ Softmax 기반 OOD 탐지 함수\n",
    "def predict_with_ood_detection(model, X, threshold=0.6):\n",
    "    probs = model.predict_proba(X)  # Softmax 확률 출력\n",
    "    max_probs = np.max(probs, axis=1)  # 가장 높은 확률 값\n",
    "    preds = np.argmax(probs, axis=1)  # 가장 높은 확률의 클래스\n",
    "\n",
    "    # 특정 확률(threshold) 이하이면 \"기타 소음\"(-1)으로 변경\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# 📌 6️⃣ OOD 탐지 적용 (테스트 데이터 & 기타 소음 데이터)\n",
    "y_pred_test = predict_with_ood_detection(model, X_test, threshold=0.8)\n",
    "y_pred_ood = predict_with_ood_detection(model, ood_X_test, threshold=0.8)\n",
    "\n",
    "# 📌 7️⃣ 결과 출력\n",
    "print(\"✅ 테스트 데이터 예측 결과:\", y_pred_test)\n",
    "print(\"✅ OOD (기타 소음) 예측 결과 (Softmax 기반 필터링):\", y_pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cea29f87-b853-49bb-b341-55db171dde0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 60)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04715eda-aa01-4430-b46f-0ec34109891c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileName', 'labelName', 'area_start', 'area_end', 'category_01',\n",
       "       'category_02', 'category_03', 'decibel', 'soundQuality', 'subCategory',\n",
       "       'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7',\n",
       "       'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13',\n",
       "       'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19',\n",
       "       'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25',\n",
       "       'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30', 'mfcc_31',\n",
       "       'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'mfcc_37',\n",
       "       'mfcc_38', 'mfcc_39', 'mfcc_40', 'mfcc_41', 'mfcc_42', 'mfcc_43',\n",
       "       'mfcc_44', 'mfcc_45', 'mfcc_46', 'mfcc_47', 'mfcc_48', 'mfcc_49',\n",
       "       'mfcc_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73cb519d-9256-4535-9055-679cc182275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16156, 82)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50658fe9-ad16-4dc7-91a3-91a233d85075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileName', 'labelName', 'area_start', 'area_end', 'category_01',\n",
       "       'category_02', 'category_03', 'decibel', 'soundQuality', 'subCategory',\n",
       "       'bitRate', 'duration', 'fileFormat', 'fileSize', 'recodingType',\n",
       "       'sampleRate', 'acqDevice', 'acqMethod', 'acqType', 'areaUse',\n",
       "       'dayNight', 'direction', 'distance', 'district', 'latitude',\n",
       "       'longitude', 'micClass', 'obstacle', 'place', 'recordingTime', 'urban',\n",
       "       'weather', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6',\n",
       "       'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12',\n",
       "       'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18',\n",
       "       'mfcc_19', 'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24',\n",
       "       'mfcc_25', 'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30',\n",
       "       'mfcc_31', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36',\n",
       "       'mfcc_37', 'mfcc_38', 'mfcc_39', 'mfcc_40', 'mfcc_41', 'mfcc_42',\n",
       "       'mfcc_43', 'mfcc_44', 'mfcc_45', 'mfcc_46', 'mfcc_47', 'mfcc_48',\n",
       "       'mfcc_49', 'mfcc_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72069b51-f47e-47c7-8a59-05528789e6b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9e76ca-cd73-4a20-8bc5-de73e72ab703",
   "metadata": {},
   "source": [
    "# df_etc2 기타 소음 (동물) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04571192-a643-4538-a1e8-bdf29e27f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/ubuntu/data/etc_noise_data_test_02\"\n",
    "\n",
    "# 기존 데이터프레임이 존재하는지 확인\n",
    "try:\n",
    "    df_combined\n",
    "except NameError:\n",
    "    df_combined = pd.DataFrame()  # 없으면 빈 데이터프레임 생성\n",
    "\n",
    "json_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "            annotation = annotations[0] if annotations and isinstance(annotations, list) else {}\n",
    "\n",
    "            # JSON 파일명에서 확장자 제거\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "\n",
    "            json_data.append({\n",
    "                \"baseName\": base_name,  # 확장자 없는 파일명 저장\n",
    "                \"fileName\": data[\"audio\"][\"fileName\"],\n",
    "                \"labelName\": annotation.get(\"labelName\", None),\n",
    "                \"area_start\": annotation.get(\"area\", {}).get(\"start\", None),\n",
    "                \"area_end\": annotation.get(\"area\", {}).get(\"end\", None),\n",
    "                \"category_01\": annotation.get(\"categories\", {}).get(\"category_01\", None),\n",
    "                \"category_02\": annotation.get(\"categories\", {}).get(\"category_02\", None),\n",
    "                \"category_03\": annotation.get(\"categories\", {}).get(\"category_03\", None),\n",
    "                \"decibel\": annotation.get(\"decibel\", None),\n",
    "                \"soundQuality\": annotation.get(\"soundQuality\", None),\n",
    "                \"subCategory\": annotation.get(\"subCategory\", None),\n",
    "            })\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "# WAV 파일에서 MFCC 추출하는 함수\n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=50):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # MFCC 평균값 반환\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {file_path} - {e}\")\n",
    "        return [None] * n_mfcc  # 오류 발생 시 None 리스트 반환\n",
    "\n",
    "wav_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        base_name = \"_\".join(file.split(\"_\")[:-1])  # \"_1.wav\" 부분 제거하고 기본 파일명 추출\n",
    "        mfcc_features = extract_mfcc(file_path)\n",
    "\n",
    "        wav_data.append({\n",
    "            \"baseName\": base_name,  # JSON과 매칭할 기본 파일명 저장\n",
    "            **{f\"mfcc_{i+1}\": mfcc for i, mfcc in enumerate(mfcc_features)}\n",
    "        })\n",
    "\n",
    "df_wav = pd.DataFrame(wav_data)\n",
    "\n",
    "# # JSON 데이터와 WAV 데이터 병합 (baseName 기준)\n",
    "df_etc2 = pd.merge(df_json, df_wav, on=\"baseName\", how=\"left\").drop(columns=[\"baseName\"])\n",
    "\n",
    "# # 기존 데이터프레임 df_combined에 추가\n",
    "#df_combined2 = pd.concat([df_combined, df_etc2], ignore_index=True)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b65a510a-a777-4dbd-9d82-f266571787b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fileName', 'labelName', 'area_start', 'area_end', 'category_01',\n",
       "       'category_02', 'category_03', 'decibel', 'soundQuality', 'subCategory',\n",
       "       'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7',\n",
       "       'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13',\n",
       "       'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19',\n",
       "       'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25',\n",
       "       'mfcc_26', 'mfcc_27', 'mfcc_28', 'mfcc_29', 'mfcc_30', 'mfcc_31',\n",
       "       'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'mfcc_37',\n",
       "       'mfcc_38', 'mfcc_39', 'mfcc_40', 'mfcc_41', 'mfcc_42', 'mfcc_43',\n",
       "       'mfcc_44', 'mfcc_45', 'mfcc_46', 'mfcc_47', 'mfcc_48', 'mfcc_49',\n",
       "       'mfcc_50'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11906ee6-67d2-4681-9acf-e6fa7d23efdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.동물_9206.wav', '7.동물_9095.wav', '7.동물_9041.wav', '7.동물_9203.wav', '7.동물_9208.wav', '7.동물_9204.wav', '7.동물_9110.wav', '7.동물_8962.wav', '7.동물_9211.wav', '7.동물_8979.wav', '7.동물_9215.wav', '7.동물_9040.wav', '7.동물_9090.wav', '7.동물_9112.wav', '7.동물_9063.wav', '7.동물_8954.wav', '7.동물_9214.wav', '7.동물_9205.wav', '7.동물_9213.wav', '7.동물_9207.wav']\n"
     ]
    }
   ],
   "source": [
    "file_names = df_etc2[\"fileName\"].tolist()\n",
    "print(file_names)  # 리스트 형태로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe283104-d649-4e27-be1f-99b73fb6b2a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2fdaa6a1e0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 📌 6️⃣ OOD 탐지 적용 (테스트 데이터 & 기타 소음 데이터)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_ood_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0my_pred_ood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_ood_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mood_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-2fdaa6a1e0ba>\u001b[0m in \u001b[0;36mpredict_with_ood_detection\u001b[0;34m(model, X, threshold)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 📌 5️⃣ Softmax 기반 OOD 탐지 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_with_ood_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Softmax 확률 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmax_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 가장 높은 확률 값\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 가장 높은 확률의 클래스\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    995\u001b[0m                       pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[1;32m    996\u001b[0m         \u001b[0;34m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m                              f\"input n_features is {n_features}\")\n\u001b[1;32m    803\u001b[0m         return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,\n\u001b[0;32m--> 804\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     predict.__doc__ = _lgbmmodel_doc_predict.format(\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   3538\u001b[0m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[1;32m   3539\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3540\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 📌 4️⃣ OOD 데이터 로드 & 전처리 (MFCC 특징 사용)\n",
    "ood_X_test = df_etc2.iloc[:, -50:]  # OOD 데이터의 MFCC 13개 컬럼 사용\n",
    "\n",
    "# 📌 5️⃣ Softmax 기반 OOD 탐지 함수\n",
    "def predict_with_ood_detection(model, X, threshold=0.6):\n",
    "    probs = model.predict_proba(X)  # Softmax 확률 출력\n",
    "    max_probs = np.max(probs, axis=1)  # 가장 높은 확률 값\n",
    "    preds = np.argmax(probs, axis=1)  # 가장 높은 확률의 클래스\n",
    "\n",
    "    # 특정 확률(threshold) 이하이면 \"기타 소음\"(-1)으로 변경\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# 📌 6️⃣ OOD 탐지 적용 (테스트 데이터 & 기타 소음 데이터)\n",
    "y_pred_test = predict_with_ood_detection(model, X_test, threshold=0.8)\n",
    "y_pred_ood = predict_with_ood_detection(model, ood_X_test, threshold=0.8)\n",
    "\n",
    "# 📌 7️⃣ 결과 출력\n",
    "print(\"✅ 테스트 데이터 예측 결과:\", y_pred_test)\n",
    "print(\"✅ OOD (기타 소음) 예측 결과 (Softmax 기반 필터링):\", y_pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6b0adc-c8b8-4406-ab7a-f0f0cd1ae31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1406f486-6e5e-4429-b6db-0d7630ebebce",
   "metadata": {},
   "source": [
    "# df_etc3 기타 소음 (df_etc1 + df_etc2) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835bf543-f01a-4937-be09-f390f3c45b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/ubuntu/data/etc_noise_data_test_03\"\n",
    "\n",
    "# 기존 데이터프레임이 존재하는지 확인\n",
    "try:\n",
    "    df_combined\n",
    "except NameError:\n",
    "    df_combined = pd.DataFrame()  # 없으면 빈 데이터프레임 생성\n",
    "\n",
    "json_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".json\"):\n",
    "        with open(os.path.join(data_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "            annotation = annotations[0] if annotations and isinstance(annotations, list) else {}\n",
    "\n",
    "            # JSON 파일명에서 확장자 제거\n",
    "            base_name = os.path.splitext(file)[0]\n",
    "\n",
    "            json_data.append({\n",
    "                \"baseName\": base_name,  # 확장자 없는 파일명 저장\n",
    "                \"fileName\": data[\"audio\"][\"fileName\"],\n",
    "                \"labelName\": annotation.get(\"labelName\", None),\n",
    "                \"area_start\": annotation.get(\"area\", {}).get(\"start\", None),\n",
    "                \"area_end\": annotation.get(\"area\", {}).get(\"end\", None),\n",
    "                \"category_01\": annotation.get(\"categories\", {}).get(\"category_01\", None),\n",
    "                \"category_02\": annotation.get(\"categories\", {}).get(\"category_02\", None),\n",
    "                \"category_03\": annotation.get(\"categories\", {}).get(\"category_03\", None),\n",
    "                \"decibel\": annotation.get(\"decibel\", None),\n",
    "                \"soundQuality\": annotation.get(\"soundQuality\", None),\n",
    "                \"subCategory\": annotation.get(\"subCategory\", None),\n",
    "            })\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "# WAV 파일에서 MFCC 추출하는 함수\n",
    "def extract_mfcc(file_path, sr=22050, n_mfcc=50):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        return np.mean(mfccs, axis=1)  # MFCC 평균값 반환\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {file_path} - {e}\")\n",
    "        return [None] * n_mfcc  # 오류 발생 시 None 리스트 반환\n",
    "\n",
    "wav_data = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".wav\"):\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        base_name = \"_\".join(file.split(\"_\")[:-1])  # \"_1.wav\" 부분 제거하고 기본 파일명 추출\n",
    "        mfcc_features = extract_mfcc(file_path)\n",
    "\n",
    "        wav_data.append({\n",
    "            \"baseName\": base_name,  # JSON과 매칭할 기본 파일명 저장\n",
    "            **{f\"mfcc_{i+1}\": mfcc for i, mfcc in enumerate(mfcc_features)}\n",
    "        })\n",
    "\n",
    "df_wav = pd.DataFrame(wav_data)\n",
    "\n",
    "# # JSON 데이터와 WAV 데이터 병합 (baseName 기준)\n",
    "df_etc3 = pd.merge(df_json, df_wav, on=\"baseName\", how=\"left\").drop(columns=[\"baseName\"])\n",
    "\n",
    "# # 기존 데이터프레임 df_combined에 추가\n",
    "#df_combined2 = pd.concat([df_combined, df_etc2], ignore_index=True)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8719e48-ed3c-4080-959d-3fb3c9c4f797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_etc3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9c23569-054a-4f2e-9809-6db00d30145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.동물_9206.wav', '7.동물_9095.wav', '7.동물_9041.wav', '3.항공기_3089.wav', '3.항공기_3096.wav', '7.동물_9203.wav', '4.열차_3548.wav', '7.동물_9208.wav', '7.동물_9204.wav', '7.동물_9110.wav', '3.항공기_65672.wav', '7.동물_8962.wav', '3.항공기_19365.wav', '7.동물_9211.wav', '3.항공기_3090.wav', '4.열차_3551.wav', '7.동물_8979.wav', '3.항공기_65674.wav', '4.열차_3807.wav', '7.동물_9215.wav', '4.열차_3806.wav', '7.동물_9040.wav', '4.열차_3554.wav', '3.항공기_65671.wav', '7.동물_9090.wav', '7.동물_9112.wav', '3.항공기_3093.wav', '3.항공기_65673.wav', '7.동물_9063.wav', '4.열차_3810.wav', '4.열차_3552.wav', '4.열차_3808.wav', '7.동물_8954.wav', '3.항공기_3092.wav', '7.동물_9214.wav', '7.동물_9205.wav', '4.열차_3809.wav', '7.동물_9213.wav', '7.동물_9207.wav', '4.열차_3547.wav']\n"
     ]
    }
   ],
   "source": [
    "file_names = df_etc3[\"fileName\"].tolist()\n",
    "print(file_names)  # 리스트 형태로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724e2f23-453a-4d6c-ac91-ed77ade6b345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 OOD (기타 소음) 예측 결과 (Softmax 기반 필터링)\n",
      "        fileName  predicted_label\n",
      "   7.동물_9206.wav                1\n",
      "   7.동물_9095.wav                1\n",
      "   7.동물_9041.wav                1\n",
      "  3.항공기_3089.wav                1\n",
      "  3.항공기_3096.wav                1\n",
      "   7.동물_9203.wav                1\n",
      "   4.열차_3548.wav                1\n",
      "   7.동물_9208.wav                1\n",
      "   7.동물_9204.wav                1\n",
      "   7.동물_9110.wav                1\n",
      " 3.항공기_65672.wav                1\n",
      "   7.동물_8962.wav                1\n",
      " 3.항공기_19365.wav                1\n",
      "   7.동물_9211.wav                1\n",
      "  3.항공기_3090.wav                1\n",
      "   4.열차_3551.wav                1\n",
      "   7.동물_8979.wav               -1\n",
      " 3.항공기_65674.wav               -1\n",
      "   4.열차_3807.wav                1\n",
      "   7.동물_9215.wav                1\n",
      "   4.열차_3806.wav                1\n",
      "   7.동물_9040.wav                1\n",
      "   4.열차_3554.wav                1\n",
      " 3.항공기_65671.wav                1\n",
      "   7.동물_9090.wav                1\n",
      "   7.동물_9112.wav               -1\n",
      "  3.항공기_3093.wav                1\n",
      " 3.항공기_65673.wav                1\n",
      "   7.동물_9063.wav               -1\n",
      "   4.열차_3810.wav                1\n",
      "   4.열차_3552.wav                1\n",
      "   4.열차_3808.wav                1\n",
      "   7.동물_8954.wav               -1\n",
      "  3.항공기_3092.wav                1\n",
      "   7.동물_9214.wav                1\n",
      "   7.동물_9205.wav                1\n",
      "   4.열차_3809.wav                1\n",
      "   7.동물_9213.wav                1\n",
      "   7.동물_9207.wav                1\n",
      "   4.열차_3547.wav                1\n",
      "\n",
      "✅ OOD 데이터에서 -1 개수: 5\n"
     ]
    }
   ],
   "source": [
    "# 📌 4️⃣ OOD 데이터 로드 & 전처리 (MFCC 특징 사용)\n",
    "ood_X_test = df_etc3.iloc[:, -50:]  # OOD 데이터의 MFCC 13개 컬럼 사용\n",
    "\n",
    "# 📌 5️⃣ Softmax 기반 OOD 탐지 함수\n",
    "def predict_with_ood_detection(model, X, threshold=0.6):\n",
    "    probs = model.predict_proba(X)  # Softmax 확률 출력\n",
    "    max_probs = np.max(probs, axis=1)  # 가장 높은 확률 값\n",
    "    preds = np.argmax(probs, axis=1)  # 가장 높은 확률의 클래스\n",
    "\n",
    "    # 특정 확률(threshold) 이하이면 \"기타 소음\"(-1)으로 변경\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# 📌 6️⃣ OOD 탐지 적용 (기타 소음 데이터)\n",
    "y_pred_ood = predict_with_ood_detection(model, ood_X_test, threshold=0.8)\n",
    "\n",
    "# ✅ 예측 결과를 데이터프레임에 추가하여 파일명과 함께 출력\n",
    "df_etc3[\"predicted_label\"] = y_pred_ood\n",
    "\n",
    "# ✅ 기타 소음(-1) 개수 카운트\n",
    "num_neg1_ood = np.count_nonzero(y_pred_ood == -1)\n",
    "\n",
    "# ✅ 출력 정리 (파일명 + 예측 결과)\n",
    "print(\"\\n📌 OOD (기타 소음) 예측 결과 (Softmax 기반 필터링)\")\n",
    "print(df_etc3[[\"fileName\", \"predicted_label\"]].to_string(index=False))\n",
    "\n",
    "# ✅ 기타 소음(-1) 개수 출력\n",
    "print(f\"\\n✅ OOD 데이터에서 -1 개수: {num_neg1_ood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d2fb5-d606-4adb-a995-b17edd059281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc9311-0d61-4674-8412-39c0dc4864d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1eadd-bf8c-4791-8d8d-a30cc2b948c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7849a9cd-e90d-442e-9afa-4f607ede619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 2479.2185\n",
      "Epoch [20/50], Loss: 2366.5955\n",
      "Epoch [30/50], Loss: 2171.6387\n",
      "Epoch [40/50], Loss: 1816.7802\n",
      "Epoch [50/50], Loss: 1286.7799\n",
      "OOD 탐지 결과: [-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-49949fc6a0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_reduced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    970\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    973\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0minit_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m         )\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3021\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3023\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   3024\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 📌 1️⃣ Autoencoder 모델 정의\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=16):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# 📌 2️⃣ 데이터 준비\n",
    "X = df_combined.iloc[:, -50:].values  # MFCC 50개 특성 사용\n",
    "y = df_combined['category_03'].astype('category').cat.codes.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# PyTorch Tensor 변환\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# 📌 3️⃣ Autoencoder 학습\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 16  # 압축할 차원 설정\n",
    "model = Autoencoder(input_dim, latent_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 과정\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, X_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 📌 4️⃣ OOD 탐지 - 재구성 오차 계산\n",
    "model.eval()\n",
    "def detect_ood(X, threshold=0.05):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructed = model(X_tensor)\n",
    "    loss = torch.mean((X_tensor - reconstructed) ** 2, axis=1).cpu().numpy()\n",
    "    return np.where(loss > threshold, -1, 1)  # 임계값보다 크면 OOD\n",
    "\n",
    "# OOD 탐지 적용\n",
    "ood_labels = detect_ood(ood_X_test.values, threshold=0.05)\n",
    "print(\"OOD 탐지 결과:\", ood_labels)\n",
    "\n",
    "# 📌 5️⃣ 차원 축소된 데이터로 LightGBM 학습\n",
    "with torch.no_grad():\n",
    "    X_train_reduced = model.encoder(X_train_tensor).cpu().numpy()\n",
    "    X_test_reduced = model.encoder(X_test_tensor).cpu().numpy()\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "lgbm.fit(X_train_reduced, y_train)\n",
    "y_pred = lgbm.predict(X_test_reduced)\n",
    "\n",
    "# 결과 출력\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"LightGBM 정확도 (Autoencoder 차원 축소 적용): {acc:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba6d52d-6925-4d15-a9da-ef19b0ff4cde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff36022-0dba-4eaf-b212-e7a6f6404982",
   "metadata": {},
   "source": [
    "# df_combined2 (df_combined + df_etc) 모델 생성 후 성능 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4769058-811b-47da-9f25-9083dbe5cc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "LightGBM 정확도: 0.8313\n",
      "\n",
      "Confusion Matrix:\n",
      "        기차  비행기  이륜차경적  이륜차주행음  지하철  차량경적  차량사이렌  차량주행음  헬리콥터\n",
      "기차       0    0      0       0    0     0      0      0     0\n",
      "비행기      0    0      0       2    0     0      0      0     0\n",
      "이륜차경적    0    1    845      13    1    75      8      6     0\n",
      "이륜차주행음   8    8     11     760    3    28     25     77     0\n",
      "지하철      0    0      0       1    0     0      0      0     0\n",
      "차량경적     2    0     54      32    1   495     17     20     0\n",
      "차량사이렌    0    2      5      15    0    21    352     18     0\n",
      "차량주행음    2    0      3      67    1     8     10    238     0\n",
      "헬리콥터     0    0      0       0    0     1      0      0     0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          기차       0.00      0.00      0.00         0\n",
      "         비행기       0.00      0.00      0.00         2\n",
      "       이륜차경적       0.92      0.89      0.91       949\n",
      "      이륜차주행음       0.85      0.83      0.84       920\n",
      "         지하철       0.00      0.00      0.00         1\n",
      "        차량경적       0.79      0.80      0.79       621\n",
      "       차량사이렌       0.85      0.85      0.85       413\n",
      "       차량주행음       0.66      0.72      0.69       329\n",
      "        헬리콥터       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.83      3236\n",
      "   macro avg       0.45      0.45      0.45      3236\n",
      "weighted avg       0.84      0.83      0.84      3236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/ml_env_python3.6/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 레이블(label)과 피처(features) 분리\n",
    "X = df_combined2.iloc[:, -50:]  # 마지막 13개 컬럼을 특성(MFCC)으로 사용\n",
    "y = df_combined2['category_03'].astype('category').cat.codes  # 범주형 데이터를 숫자로 변환\n",
    "\n",
    "# 범주형 데이터(레이블) 숫자로 변환\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "# 클래스 레이블 매핑\n",
    "class_labels = df_combined2['category_03'].astype('category').cat.categories\n",
    "\n",
    "# 데이터셋 분할 (train: 80%, test: 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_classes = len(set(y))\n",
    "print(num_classes)\n",
    "    \n",
    "# LightGBM 모델 정의 및 학습\n",
    "model2 = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "# 평가 결과 출력\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"LightGBM 정확도: {acc:.4f}\")\n",
    "\n",
    "# 혼동 행렬 및 분류 보고서 출력\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), index=class_labels, columns=class_labels)\n",
    "print(conf_matrix)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_labels.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4500a507-b115-4e7e-a70f-b9b9f59ffd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OOD (기타 소음) 예측 결과 (Softmax 기반 필터링): [ 5  0  3  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  6  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5\n",
      "  5  2  2  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  3  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  5  5  5  5  5  5  3  5  5  5  5  5  5  3  5  5  5  0  5  2  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  2  2  5  5  5  5  5  5  5  2  2  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  2  5  2  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  2  5  5  2  5  5  5  5  5  5  0  0  0  5  5  2  2  2  2\n",
      "  2  5  5  5  5  5  5  5  5  5  2  0  5  2  2  5  5  2  5  0  5  5  5  5\n",
      "  5  5  2  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  6  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  0  5  5  5  5  5  5  5  2  2  2  2  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  2  5  2  5  5  5  2  2  5  5  5  5  5  5  5  5  5\n",
      "  2  2  2  2  2  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5\n",
      "  5  5  5  5  5  5  2  5  5  5  5  5  5  5  2  5  5  5  5  5  2  5  5  5\n",
      "  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  0  0  0  5  2  5  5  5  5  5  0  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  2  5  5  5  5  5  5  5\n",
      "  2  2  5  5  5  5  5  1  5  5  5  5 -1  0  0 -1  5  5  2  5  5  5  5  5\n",
      " -1  5  5  5  5  5  5  2  5  5  2 -1  5  2  7  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  2\n",
      "  5  5  5  5  5  5  5  5 -1  5  5  5  5  5  5  5  5  5  5 -1  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  3  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  1  5  5  5  5  6 -1  5  2  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  7  2  5  5  5  5  5  5  5  2  5  6  5  5  5  1\n",
      "  5  5  5  5  5  5  5  5  5  5  5  3  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  3  5  5  5  5  5  5  5  5  5  2  5  5  5  5  3  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  2  5  5  5  5  5  5  5  5  5  2  5  5  5  5  2  5  5  5  5  5  5  2  5\n",
      "  5  2  5  5  5  5  1  5  5  5  5  5  5  3  5  5  5  5  2  2  2  5  5  5\n",
      "  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  0  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  2  2  5  2  5  5  2  5  5  5  2  2  2  5  5  5\n",
      "  2  5  5  5  5  5  5  5  2  5  5  2  5  5  5  0  5  2  2  5  5  6  5  5\n",
      "  5  5  5  3  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  3  5  2\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  2  2  5  5  5  5  2  2  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  7  5  5  5  5  5  5  2  5  5  2  5  5\n",
      "  5  5  5  5  2  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  2  5  5  5\n",
      "  5  2  5  5  2  0  5  5  5  5  5  5  5  5  5  5 -1  6  5  2  5  3  5  6\n",
      "  5  5  5  5  2  5  5  5  5  5  5  5 -1 -1  5  5  2  5  5  5  2  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  2  5  5  5  5  2  5  6  2  0  5  5 -1  3 -1  5  5 -1 -1  7  5  5\n",
      "  5  5  5  5  5  2  7  5  5  5  5 -1  5  5 -1  3  5  5  5 -1  3  5  5  5\n",
      " -1  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 -1  5  5  2  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  3  0  5  2  0  5  5  5  5  5  5  3  5  5  5  0  0  5\n",
      "  5  5  5  7  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2\n",
      "  5  5  5  5  5  0  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  6  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  2  5  2  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  2  5  2\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  2  5\n",
      "  5  5 -1  5  2  7  5  2  2  5  2  5  2  5  5  5  5  5  5  2  5  5  5  3\n",
      "  5  5  7  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  1  5  5\n",
      "  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  3\n",
      "  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  2  6  5  6  0  5  0  0  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  2  5  5  5  6  5  5  5  0  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  6  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  2  5  2  5  5  0  2  5  5  5  2  5  5  5  5  5  5  5\n",
      "  5  5  5  3  5  5  5  5  5  5  5  5  2  7  5  5  5 -1  5  5  5 -1  1  5\n",
      "  5  5  5  5  5  5 -1  5 -1  5  5  5  5  5  5  2  3  5  5  5  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  6  3 -1  2  5  3\n",
      "  5  5  5  5  5  5  2  3  2  5 -1  5  5  5  5  5  5  5  5  5  5  2  5  3\n",
      "  3  5  5  2  5  5  5  5  2  5  5  2  5  5  5  5  5  5  2  5  5  5  5  5\n",
      "  5 -1  5  5  2  7  5  5  5  5  5  2  5  5  5  5  5  2  5  5  5  5  5  5\n",
      " -1  2  5  5  5  5  5  5  2  5  5  5  5  2  5  5  7  5  5  5  5  5  5  5\n",
      "  5  2  2  5  5  5 -1  6  5  5  5  5 -1  5 -1  5  5  5  2  5  5  5  5  5\n",
      "  5  3  5  3  2  5  5  5  5  5  5 -1  5  5  5  5  5  5  7  5  5  5  2  5\n",
      "  3  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5 -1\n",
      "  5  5  5  5  5  6  5  5  5  5  3  5  5  5  5  2  5  5  5 -1 -1  5  5  7\n",
      "  2  5  5  5  5  5  5  5  5  5  2  5  5  2  5  5  5  2 -1  5  5  5 -1  5\n",
      "  5  5  2  5  5  5  5  5  5  2  5  5  5 -1  5  5 -1  5  5 -1 -1 -1  5  5\n",
      "  5  5  2  5  5  5  5  3  5  2  5  5  2  5  5  5  5  5  5  5  5  5  7  5\n",
      " -1  5  5  5  5  5 -1  5  5  6  5  2  5  5  5  5  3  5  5  5  5  5  2  7\n",
      "  5  5  2  5  5  5  5  5 -1  5  5  5  5  5  2  5  5  2  5  5 -1  5  3  5\n",
      "  5 -1  5  5  2  5  5  5  5  5  5  5  2  5  5  5 -1  5  5  5  5  5  5  5\n",
      "  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  5  5  5  5\n",
      "  5  5  2  5  5  5  5  5 -1 -1  7  2 -1  5  2  5  5  5  5 -1  5  5  3  5\n",
      "  5  5  5  5  2  5 -1  5  5  5  5 -1  5  5  5  6  5 -1 -1  5  5  5  5  5\n",
      "  5 -1  6  5  5  5  2 -1  5  5  5  5  5  5  5  7  2  5  5  5  6  5  5  5\n",
      "  5  5  5  5  5 -1  5  5  2  5  5  2  5  5  5  6  3  3  5  5  5  5  6  5\n",
      "  5 -1 -1  5  5  5  5  5  5  5 -1  5  5  5  5  5  5  5  5  5 -1  5  5  5\n",
      "  5  5  5  5 -1  5  5  5  5  5 -1 -1  5  5  5  5  5  5 -1  5 -1 -1  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  5  5  3  5  5  1\n",
      "  1  5  5  5 -1  5  5  5  5 -1  5 -1 -1  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  7  5  5  5  5  5  2  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  6  5  5  5 -1  5  5  5  5  5  5  5  5  5  5  5  5  5  5 -1  5  7  5  5\n",
      "  5  5  5  5 -1  5  5  5  5  5  5  5  5  5 -1 -1  2 -1 -1  3 -1  5 -1 -1\n",
      "  5  5  5  5 -1  5  5  5  5  2  5  7  3 -1  5  5 -1  5 -1  5  3  5  5  5\n",
      "  5  3  5  5  2  3  5  5  5  5  5 -1  5  5  5 -1  5  5  5  5  5  5  5  5\n",
      "  5  5  5  6  7  5  5  5  5 -1  3  2  7  5  5  5  5  5 -1  5  7  5 -1  2\n",
      "  5  5 -1  5  5  5  5  5  5  5  5  5 -1  3  5 -1 -1 -1  5  5  5  3  5  5\n",
      "  5  5  5 -1  5  5  3 -1  3  5  6  5  5  5  5  5  5  5  5  5  5  5  6  5\n",
      "  5 -1 -1  2  5  5  5 -1  5  5 -1  5  5  5  5  5  5  5  3  5  5  5  5  5\n",
      "  5 -1 -1 -1  5  5  5  5  5  3  5  3  5  4  6 -1  5  5  5  5  5 -1 -1  5\n",
      "  5  5  5  5  5  5  5  5  5  3 -1  5  5  5 -1  2  6  2 -1  5  5  3  5  5\n",
      " -1  5  5  5  5 -1  7 -1  6  3  5  5  5  5  3  5  5  2  5 -1  5 -1  5  5\n",
      "  5 -1  5  5  5  5  5  5  5 -1 -1  5  5 -1  5  5  5  5 -1 -1  5  5  5  5\n",
      "  7  5  5  5  3  7  5 -1  5  3 -1  5  5 -1  5 -1 -1  5  5  5  5  5  5  5\n",
      "  5  5  5 -1  5  5  5 -1 -1  5 -1  5  5  5  5  5  5  5  5  5  5  6  5  5\n",
      " -1  5  5  5  5 -1 -1  5  7  5  7  5  5  5  5 -1 -1  5  3  5  5  5 -1  5\n",
      "  3 -1  3  5  5  5  5  5  5  5 -1  2  5  5  5  5  2  3  5  2  5  5  5  5\n",
      "  5  5  5  5 -1 -1  5  5  2 -1  5  5  5 -1  5 -1  5  5  3  5  5  6  5  5\n",
      "  5  5  5 -1 -1  5  2  5  5 -1  5 -1  5  5  7  5  5  5  5 -1  5  5 -1  5\n",
      "  5  5  5  5  5  5  5  5 -1  5  5 -1  5  5  5  6  5  5  5  5  3  5  5  5\n",
      "  5  5  5  5  5  5  3  3  5  3  5  5  5  5  5  5  5  5  5  5  5  5  5  5\n",
      "  5  5 -1  5 -1  5  5  5  5  5  5  5  5  5  5  5 -1 -1  5 -1  5  7 -1  5\n",
      "  5  5  5  5  5  5  5  5  5 -1 -1  3  3 -1  5  5  5 -1  5 -1  5  5  5  5\n",
      "  3  5  5  5  2  5  5  5 -1  5  5  5  5  5  5  6  5  6  5 -1  5  3  5  5\n",
      "  5  5  6  5  5  5  5  5  5  5  5  5 -1 -1  5  7 -1 -1  5  5  5  3  5  5\n",
      "  5  5  5  5  5  5  2  5  5  5  6  5  5  5  5 -1  2 -1  5 -1  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  7  5  5  5  5  5  5  5 -1  5 -1 -1 -1  5  5\n",
      "  5  5  2  5  5  5  5  5 -1  5  5 -1  5  5  2 -1 -1 -1  5  5  5  2  5  3\n",
      "  5 -1  5  5  5  5  5  5  2 -1  5  5  5  5  5  5  5  5  2  5  5  5 -1  5\n",
      "  5  5  5  5  5  5  2  5  5  7  5  5  3  7  3  5  5  5  2  5  5  5  5  2\n",
      " -1  5  5  5  5  5  3  0  5  2  5  5  5  5  5  5  2 -1  5  3  5  6  6  6\n",
      "  6  6  6  6  3 -1  6  6  6  6  6  6 -1  6  6  6  6  6 -1  6  6 -1 -1 -1\n",
      "  6 -1  6  6  6  6  6  6  6  6  6  6 -1  6  6  2  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  5  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  3\n",
      "  6  6  6  6  7  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  6  6  6  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  7  3  6  6 -1  6  6  6  6 -1 -1  3  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  5 -1  6  6  6  6  5  6  6  6  6  6  6  6  6 -1  6  6  6\n",
      "  6  6  5  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  6 -1\n",
      "  6  6  6  7  6  6  5  5  6  6  6  6  6 -1  6  6  6  3  6  6  6  6  7  6\n",
      "  6  1  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6 -1  6\n",
      "  6  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6\n",
      "  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5 -1  3  5  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6 -1  6  6  6  5  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  6  6  6 -1  6  6  6  6\n",
      "  6  6  6  6  6  5  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  3  6  6  6  6  6  6  6  6 -1  6  5  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  5  2  6  6  6  6 -1  6  6  6  6  6  6  6\n",
      " -1 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  6  7  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  3  6  6  6  3  6  6  6  6\n",
      "  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  3  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  7  6\n",
      "  6  6  6  6  1  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6\n",
      "  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  7  6\n",
      "  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6\n",
      "  7  6  6  6 -1  6  6  6  6 -1 -1  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  3  6  6  6  6  6  5  5  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  2  2  6  6  6  6  5 -1  6  6 -1  5  6  6  6  6  6  6  6  5  6  6  6\n",
      "  6  6  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  2  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6 -1 -1  6  6  6\n",
      "  6  6  6  6  6 -1 -1  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  3  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6 -1  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6\n",
      "  6  6  6  6  6  5  6  6  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1\n",
      "  6  5  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      " -1  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  3  6  6  6  6  6  5  6\n",
      "  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  7  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  2  6  5  6  6  6  5  6  6  6  6  6  7  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6  2  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  2  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5 -1  6\n",
      "  6  6  6  6  6  6  6  6  3  6  6  6  6  6  6  6  6  6  6 -1  6  6  6  6\n",
      "  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  2  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  3  6  6  6  6  6  6  6  6  6  7  6  6  6  6  6  6  5  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6 -1  6  6  6  6  6  6  7  6  6  6  6  6  6  6  5  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6\n",
      "  6  5  6  6  3  6  6  6  6  6  6  6 -1  6 -1  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  3 -1  6  6  6  6  6  6  7  6  6  6  5  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6 -1  6  6  6 -1  6\n",
      "  6  6  6  6  6  6 -1  6  6  6  2  6  6  6  6  6  6  6  6 -1  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6  6  6  6  6  5  6\n",
      "  6 -1  6  6  6  6  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6  6  6  6  6\n",
      "  6  6 -1  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  2  6  6  6  6  6  6  6  1  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6 -1  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  5  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  3  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  2  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  5  6  6  6  6  6\n",
      "  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6 -1 -1  6  6  6  6  5  6  6  6  6  6  6  6  6  6  6  6  7  6\n",
      "  6  6  6  5  6  6  6  6  6  6  6  6  5  6  6  6  6  6  6  6  6  6  6  6\n",
      "  6  6  6  6  6  5  6  6  6  6 -1  6  6  6  6  6  6  6  6  7  3  7  7  7\n",
      " -1  7 -1  7 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  7  3  7  7  3  7\n",
      "  7  7  7 -1  7  7  7  7  7  7  7  7  3  7  7  7  7  2  7  7  7 -1  7  7\n",
      "  3 -1  7  7  7  7  7  7 -1  7  7 -1  7  7  7 -1  7  7  6  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7 -1  7  3  7  7  7  7  7  7  7 -1  7  7  7  7 -1  7\n",
      "  7  3  7  7  7  7  7  7  7  7  7  7  7  3  7  7 -1 -1 -1  7 -1 -1  7  7\n",
      "  7  7  7  3 -1  7  7  3  7  3  3  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7 -1 -1 -1 -1  7  7  7  7  7  7  7  7  7 -1  7  7  3  3  7\n",
      "  7  7  7  7  7  7  3 -1  7  7  7  7  7  7 -1 -1  7  7  7  3  7  7  7  7\n",
      "  7  3  7  7  7  7  7  7  7  3  7  3  7  7  7  3  7  7  7  7 -1 -1  3  7\n",
      "  3  7  7  7 -1 -1  7  7  7  7  3  7  7  7  7  7  3  7  7  7  7  7  7  7\n",
      " -1  7  7  7  7  7  7  7  3  7  3  7  7  7  7  7  7  6  7  7  7  7  7 -1\n",
      "  7  7  7  7  7  7 -1 -1  6  7  7  7  7 -1  7  7  7  3  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7 -1  7  7 -1  7 -1 -1  7  7  7  7  3  7  7  7  7  7  7\n",
      " -1  7  7  7  7  7  7  7  7  6  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  3  3  7  7  7  7  7  7  3  7  7  7  7  7  7  7  7 -1  7  7  7 -1  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  6  7  7  7  7  3  7  7 -1\n",
      "  7  7  7  7 -1  7  7 -1  3  7  7  7  7  7  7  7  3  7  3 -1  7  7  7  7\n",
      "  7  7  7  7  7  3  7 -1  7 -1 -1  7  3  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  3 -1  3  7  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7  7  7  7  7  7  7 -1  7  7  7  7  7  3  3  3  7 -1  7 -1  7  7  7  7\n",
      "  7  7  7  7 -1  7  7  7  7  7  7  7  7  7  3  7  7  7 -1  7  7  7  7 -1\n",
      "  0  7  7  7  7  7  7  7  7  3  7  7  7  7 -1  7  3  7  7  7  7 -1  7  3\n",
      "  7  7  7  7  7  7  7  7  7  7 -1  7  7 -1  7  7  3  7  7  7 -1  3  7  7\n",
      "  7 -1  7  7  7  7  7  7  7  7  7  7  3  7  7  7  7  7 -1  7  7 -1  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  6  7  6 -1  7  7\n",
      "  3 -1  6  3  7  7  7 -1 -1  7  7  7  7  7 -1  7  7  7  7  7  7 -1 -1  7\n",
      " -1  3 -1  7  7  7  7  3  3  7  7 -1  7  7  7 -1  7  7  3  7  7  7  7  3\n",
      "  7  7  7  7  7  7  7  7  3  7  7  7  7  7 -1  7  6  7  7  7  7 -1 -1 -1\n",
      "  7  7 -1  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  7  7  7  7  7  3\n",
      "  6  3  7  7 -1  7  7  7  7  7  3  7  7  7  7  3  7  7  7 -1  7  7 -1  7\n",
      "  7  7  7  7  7  3 -1  3  7  7 -1  7  7 -1  7  7  7  7  7 -1 -1  3  7 -1\n",
      "  3 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  7  7  7\n",
      "  3  7  7  7  7  7  7  7  5  7  7  7  7  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7  7 -1  7  5  7 -1  3  7 -1  7  7  7  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7 -1  3  3  7 -1  7 -1  0 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  5  7  7  7  7  7  7  7  7  7  7  7  7  7  7 -1\n",
      " -1  7  7  3 -1  7  3  7  7  4  7 -1  7  7  7  7  3  7  7  7  7  7  7 -1\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7 -1  7  7 -1  7  5  7  7  7\n",
      "  3  7  7  7  7 -1  3  7 -1 -1 -1  3  3 -1  7  7  7  7  7  2 -1  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7 -1  3  7  7  7  7  7  7  7  7  7  7\n",
      " -1  7  7  7  7  7  7 -1  7  3  7  7  7  7  7  7  7 -1 -1  7 -1  7 -1  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  3  7  3 -1  7  7  7  7  3 -1  7  7 -1\n",
      "  7  7  7 -1  7  7  7 -1  7  3  7  7  7  7  7  7  3  7  7 -1  7  7  3  7\n",
      "  3  7  7  7  7  3  7  7 -1  7  7  7  3  7  7  7  7  7  7  7  7 -1  7  7\n",
      "  7  7 -1  7  3  7  7  7  7  5  7 -1  7 -1 -1  7 -1  7  7  3  7  7 -1  7\n",
      "  7  3  3  7  7  7 -1 -1  7  7  7  7  7  7  7  7  7  6  7  7  7  7  7  7\n",
      "  3  7  7  3  7  7  7  7  7  7  7  7  7  3  7  7  7 -1 -1  2  3 -1 -1  7\n",
      "  7 -1  2  7  7  7  7  7  7  3  7  3  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7 -1  2  7  3  7  7  7  7 -1 -1  5  3  7  7  7  7  7  7  7  7  7 -1\n",
      " -1  3  7  7  7  7  7  7  7  7  7  7  7  7  2  7 -1  3  7  7  7  7  7  7\n",
      "  7  2  7  7 -1  7  7  7  7  7  7  7  7  7  5  7  7  7  7  7  7 -1  7  6\n",
      "  7  7  7  7  7  7  3  7  7  7 -1  7  7  3  7  7 -1  7 -1  3  7  7  7  7\n",
      "  7  7  3  7  7  2  7  7  7  7  7  7  7 -1  7  3  7 -1  7  7  7  7 -1  7\n",
      " -1 -1 -1  7  7  7  7  7  7  7  7  7  7  7  7  7  3  3  7  7  3  5  7  7\n",
      "  3  7  7 -1  7  3  7  7  2  7  7  7  7  7  7  7  7  7  3  7 -1  7  7  7\n",
      "  7  7  7  7  7  7  7  7  3  7  3  7  7  5  3  7  7  3  7 -1  7  7  7  3\n",
      "  7  7  7  7  7 -1  7 -1  7  7  7  7  7  7  7 -1  7  7  7  7 -1  7  3 -1\n",
      "  7  7  7  7  7  7  3  7  7  7  7 -1  7 -1  3  7  7 -1  7  3 -1 -1 -1  7\n",
      "  7  7  7  7  7  7 -1  7  3  7  3  7 -1  7  7  7  7 -1  7  7  7 -1  7  7\n",
      "  7 -1  7  7  7  3  7  7  7  7  7 -1  7  7  7  7  7 -1 -1  7  7  7  7  7\n",
      "  7  7  7  7 -1 -1  7  7  7  7  7  7  7  7  7  7 -1  7  7  7  7  5  7  3\n",
      "  7  7  7  7  7  7  7  7  3  7  3  3  3  7  7 -1 -1  3 -1  7  7  7  7  7\n",
      "  7  7  7  7  7  7 -1  7  7  7  7  7  7  7  7  7  7  3 -1  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  3  7  7  7  7  7  7  2  3  7  7  7  7  7\n",
      "  7  7  7  7 -1  0  7  7  7  7  7  7  7  7 -1  7  7  7  7  7  7  7  7  7\n",
      "  2  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7  7\n",
      "  7  7  7 -1  7  7  7  7 -1  7  7  7  7  7  7  7  7 -1  7  7  7  7  2  7\n",
      "  7 -1  7  7  7  7  7 -1  7  7  6  7  2  2  7  7  7  7  7  3 -1  7  7  7\n",
      "  7  7  7  7  3  7 -1  7  3  3  7  3  7  7  7  7  7  7  7  7 -1  2  2  2\n",
      "  2  2  5  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  3  2  3  2  5  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  5  2  2  5  2  2\n",
      "  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  5  2  2  6  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  7\n",
      "  7  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  3  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  7  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  5  2  2  2  3  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  5\n",
      "  2  2  2  2  2  2  0  2  2  2  2  2  2  2  2  2  3  5  5  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2 -1  5  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  5  5\n",
      "  2  2  2  2  2  2  2  6  2  2  2  2  2  2  2  2  2  2  2  2  5  5  5  5\n",
      " -1  5  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  7  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2  2  2  5  2  2 -1  2  2  2\n",
      "  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2\n",
      " -1  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2 -1  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  5  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  5  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  5  5  2  2  5  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  5  5  5  5  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  5  2  5  2  2  2\n",
      "  5  2  2  2 -1  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  7  2  2\n",
      "  2  2  2  2  5  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2\n",
      "  2  3  3  2  2  2  2  1  2  5  2  2 -1  2  2  2  2  2  2  2  2 -1  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2\n",
      "  2  3  2  3  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  6  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  5  2  2  5  2  2  2 -1  6  2  2  2  5  2  2\n",
      "  2  5  2  2  2  2  5  2  2  2  2  2 -1  2 -1  2  3 -1  2  2  2  2  2  2\n",
      "  6  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  6  2  2  2  2  2\n",
      "  2  2  2  2  2  5  5  5  2  2  3  2  5  5  2  2  2  2  2  2  2  2  2  2\n",
      " -1  5 -1  2  2  2  2  2  2  2  2  2  2  5  2  5  2  2  2  2  2  2  2  2\n",
      "  7  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  6  2  2\n",
      "  5  2  2  2  2 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  3  2  2 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  6  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5 -1\n",
      "  5  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  3  2  2  2  2  2  7  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      " -1  2  2  2 -1  2 -1  6  2  2  5  2  2  2  5  5  2 -1  6  2 -1 -1 -1  2\n",
      "  2  3  2  4 -1  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  6  2  3  2  2  2  2  2  2  2  2  2 -1  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  6  2  2  2  2  5  2  2  2  2  2  5  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  3  2  2  2  5 -1  2  2  2  2  2  3  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2 -1  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  5  2  2  2  2  2  5  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  0  5\n",
      "  6  0  0  2  5  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2\n",
      "  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2 -1  5  5 -1  2  2  2\n",
      "  2  2  2  2  2 -1 -1 -1 -1  2  5  5  3 -1  3  2 -1  2  5  3  5  5  2  5\n",
      " -1  2 -1 -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2\n",
      "  2  2  2  2  2  2  2  5 -1  5  5  3  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  1  2  2 -1 -1 -1 -1  2  5\n",
      "  2  2  2  2  2  2  2  2  2 -1 -1 -1  5  2  2  2  2  2  5  2 -1  3  2  2\n",
      "  2  2  2  2  2  2  2  2  2  3  6  2  2  2  2  2  2  2  5  5  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  7  2  2  2\n",
      "  2  3  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2\n",
      "  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  5  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  5  5  5  5  5 -1  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2 -1  2  2  2  5 -1  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  5  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  6 -1  5 -1  7  5  2  2  2  2  2  2  2\n",
      " -1  5 -1 -1  5 -1  5 -1  2 -1  5  2  2  5  2  2  2  2  5  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  5  2  2  2  2  5  2  2  2  5  2  2  2  2 -1  5 -1  2\n",
      " -1  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  5  3  2  2  2  2  2  2  3  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5  2\n",
      "  2  2  2  2  2  2  2  2  2  5  2  5  2  2  2  5  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  5  2  2  5  2  5  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5\n",
      "  2  2  2  2  2  2  2  2  2 -1 -1 -1  5  2  3  5  3 -1 -1 -1 -1 -1  2 -1\n",
      "  3 -1 -1 -1  5 -1  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 -1 -1  2  2\n",
      "  2  2 -1  2  2  5  3  2  2  2  2  3  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  5  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  5  3 -1 -1  5  2 -1  5 -1  5  5 -1 -1\n",
      "  5 -1  2  2  2  2  2  2  2  2  2  2  2 -1 -1  5 -1 -1 -1 -1 -1 -1  5  5\n",
      " -1 -1 -1  2  5 -1  5 -1  5 -1  3 -1 -1  2  2  5  6 -1 -1  3  2 -1 -1 -1\n",
      " -1  7  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  5 -1\n",
      "  2  2  2  2  2  2  2  2  5  2  5 -1  2  2  2  2  2 -1  2  2 -1 -1 -1 -1\n",
      "  4 -1  5 -1  5  5 -1  6 -1  2  7  2  2  2  5  2  2  5 -1  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  5  2  2  2  2  2  2  2  2  5  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
      "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  3  3  3\n",
      "  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  0  3  3  3  3\n",
      "  3  3 -1 -1  3  3 -1  3  3  3  3  3  3  3  3  3  3 -1  3  7 -1  3 -1 -1\n",
      "  3  3  3  3 -1  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3 -1  3  3  3 -1  3  3  7  7  3  3  7  3  3  3  3  3 -1  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  0  3 -1  3  3  7  7  3  3 -1  3  3  3 -1  3 -1\n",
      "  3  3  3  3 -1 -1  5  3  3  3  3  3  3  3  3 -1  3  3 -1  3  3  3  3  3\n",
      "  3 -1 -1  3  3 -1 -1  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  7  3  3  3 -1 -1  3  7  3  3  3 -1  3  4  3  3 -1  3  3\n",
      "  3 -1  3  7  3  2  3  3  3  3  3  3  3  3 -1  3  7  3  3  3  3  3 -1  3\n",
      "  3  3  3  1  3  3 -1 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3 -1  3  7  0  3  3  3 -1  3  3 -1  3  3  3  5 -1  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  7  7  3 -1  3  3 -1  3 -1  7  3 -1  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  6 -1  7  3  3  3  7  3  3 -1  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3  3  3  3 -1  0  3  3\n",
      "  3 -1 -1  3  3 -1  7  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  6 -1  3  3  3  3 -1  3  3  1 -1  3 -1  3  3  3  3  7  3  7  7  3 -1  3\n",
      " -1 -1  7  3 -1  3  3  3  3  3  3 -1  3  3 -1  3  3 -1  7  3  3  3  3  3\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3  3  7  3  3  2  3\n",
      "  7  5 -1  3  5  3  3 -1  3  3  3  5  3  3  3  2  3  0  3  3  3  5  3  3\n",
      "  3  3  3  3  3  3  7  3  3  3  3  3  3 -1 -1  3  1 -1  3  3 -1  3 -1  3\n",
      "  3  7  3 -1  3  3  3  3  3 -1  3  3  3 -1  3  7  3  3  3  3  3 -1  3  3\n",
      "  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  1  3\n",
      "  3  3  3  6  3  3  3  3  3  3  3  3  3  5  3  3  3  6  3  3  3  3  3  7\n",
      "  3  7  3  3  3  3  3  3  3 -1 -1  5  3  3  3 -1 -1  3  6 -1  3  5  3  3\n",
      "  3  3  3 -1  3  3  3  7  3 -1  3  3  3  3  3  3  3  2  3 -1  3  7  3  3\n",
      "  3 -1  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  7  3  7  2  3  3  7  3  3\n",
      "  3  7  3  3  7  3  3 -1  3  2  3  7 -1  3  3  3  3  3  3 -1  3 -1  3  3\n",
      "  7 -1  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3 -1  3  3  3  3  3\n",
      " -1  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  6  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3 -1  3  3  3 -1  3\n",
      "  3  3  3  3  3  3  3  7  3  3 -1 -1  7  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  7  3  3  3 -1  3  5  3  3  3  3  2  3  3  5\n",
      "  3  3  3  3  3  3  7  3  3  3  3  3  7  3 -1  2  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      " -1  3 -1  3  3 -1  3  3 -1  2  6  3  3  3  3  5  3  3  3  1  3 -1  2  3\n",
      "  3 -1  3  2  3  3 -1  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3\n",
      "  5  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1 -1  3  3  3  3\n",
      " -1  3  3  3  3 -1  3  7 -1 -1 -1  3 -1  3  3  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3 -1  5  3  3  3  3  3  3  3  3  3  3  3  3  7  3\n",
      "  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  2  3  3  3  3\n",
      "  3 -1  3  3 -1  3  3  3  3  3 -1  3  3  3  3  3  3  3  3 -1  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3 -1  3 -1  3  3  3 -1  3  3  3  3  3  3  7  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6 -1 -1  3  3  3\n",
      "  3  7  3  3  3 -1  3  3  3  3 -1  2  3  3  3  3  3  3 -1 -1 -1  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  7  6  3  3  3  3  3  3  2  3\n",
      "  3  7  3  3 -1  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7 -1  3 -1  3  3  3\n",
      "  3  3  3  3  3 -1  3  3  3  3  7  3  5  3  3  3  3  6  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7 -1  3  3  3  3  3\n",
      " -1  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  6  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3 -1 -1 -1  3  3  3  3  5  3  2  3  3  0  3  3  3  5 -1\n",
      "  3  3  3  3  3  3 -1  3  3 -1 -1  3  3  7  3  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  7\n",
      "  3  7  3 -1  0 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  7  7  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  7  3  3  3  3 -1  3  3\n",
      "  3  3  3  3 -1  3  3  3  5  3  3  3  3  3  3  3  3  3  7  6  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6 -1  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  6  3  3 -1  3  3  3  7  3  3  3  3 -1 -1  3\n",
      " -1  3  3  3  3  3  3  7  3 -1  3  7  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  5  3  3  3  2  5  3 -1  6  3 -1  3  3  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  6  3  3  3 -1 -1  3  3  3  3  3  3  3  0  3  3  3 -1  3  3 -1  3\n",
      "  3  3  3  3  3  3  3  0  0  3  3  3  3  3  0  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  0  3  3\n",
      " -1  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3\n",
      "  3  7  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3\n",
      "  7  3  3  3  3  3 -1  3 -1  3 -1  3  3  3  3  3  3  6  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  5  3  3  3  3  6  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1  3  3\n",
      "  3  3  3  3  3  3 -1 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3\n",
      "  7  3  3  3  3  3  3  3  3  2  3  3  3 -1  3  3  3  3  7  3  6  3  3  3\n",
      "  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3 -1\n",
      "  3 -1  6  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  6  3 -1  3  3  3  3  3  3  3  3  3  5  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3  3 -1  3  3  3  3  3  3 -1  3  3  3  3  3 -1  3  3  3\n",
      "  3  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3 -1  3  3\n",
      "  3  3  3  3  7  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3 -1 -1  3  3  3  3  3  3  3  3  3 -1  1  3  3  3  3  3  3\n",
      "  3  3  3  3  2  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  7  3  3  3  7  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  7  3  3  3 -1  7  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  5 -1  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3 -1  3  3  3  3  5  3 -1\n",
      "  3  3  3  3 -1  3  3  3  3  7  3 -1  3 -1  3  3  3  3  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  6  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  5  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  6  3  3 -1  3  3  3  3  3  3  3 -1  5  3  3  3  3  3  3  3  3\n",
      "  7  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  5  3  3  3  3\n",
      "  4  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3\n",
      "  3 -1  3  3  3  3  3  3 -1  3 -1  6  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  6  1  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  6  3 -1  2  3\n",
      "  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  6 -1\n",
      "  3  3  3 -1  3  3  3  3  3  3  4  6  3  3  3  3  3  3  5  3  3  3 -1  3\n",
      "  3  3  3  3  3 -1  3 -1  5  3  3  7  3  3  5  3  3 -1 -1  3  3  3  3  3\n",
      "  3  3 -1  3  3  3 -1  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  7  3  3  3 -1  3\n",
      " -1  3  3  3  3  3  3  3  7  7  3  3  3 -1  3  3  3  3  3  3  3  3  3  5\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3 -1  3\n",
      "  3  7  3  3  3  3  3  3  3  3 -1  3 -1  3 -1  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  6  3  7  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  7\n",
      "  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  7  3  3\n",
      "  3  3  3  3  3  3  3 -1 -1  3  3  3  6 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3\n",
      "  3  3  7  3  3  3  3  6  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3 -1  3  3  3\n",
      "  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  6  3  3  3  7  3  3  3  7\n",
      "  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  3\n",
      "  3  6  3  3  3  3  3  3  7  3  3  3  3  3  3  0  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  6  3  3  3  3  2  3  3 -1 -1 -1 -1  3  3  3  3  3  7  3  3\n",
      " -1  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3 -1  3  3  3  3  3  3 -1  3  3  3  3  6  3  3  3  3\n",
      "  3 -1  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  6  3  3  3  3  3  3  3  3  7  3  3  3 -1  7  3  3  3 -1  3  3  3\n",
      "  3  3  5 -1  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3 -1  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3\n",
      "  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  5  3  3 -1  3  3  3  3  3 -1  3 -1  3  3  3  3  3  3  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  3  3  3  3 -1  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  5  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3 -1\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  5 -1\n",
      "  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  7  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  5  3  6  3  3 -1  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3  3  3  2  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3 -1  6  3  3  3  3  3  3  3  3  3  3  3  3  3  5  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  7  5  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3\n",
      "  3 -1  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3  3  3  3  3  3  3\n",
      "  6  3  3  3  3  3  3  3  3  3 -1  3 -1  3 -1  3  3  3  3  3  3  3 -1  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3  3  3\n",
      "  2  3  3  3  3  3  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3  7\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  7\n",
      "  3 -1  3  3  3 -1  3  3  3  3 -1  3  3  3  3 -1  3  3  3  3  3  3  3  3\n",
      "  3  3  3  2  3  3  3  7  3  3  3  3  3  3  3  3  3  3  3  3  3  7 -1  3\n",
      "  3  3  3  3  3  3 -1  3 -1  3  3  3  3  3  3  3  5  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  5  3 -1  3  3  3  3  3  3 -1  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  7  3  3  3  3  3  3  3  5  3  3  3  3  3  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3 -1  3  3 -1  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      " -1  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  6  7  3  3  3  7  3\n",
      "  3  3  3  3  3  3  3  3  7  3  3  3  3  3  3  3  3  3  3  7 -1  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  6  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3 -1  3  3  3  3  3  3  3  7  3  3  3  3  3  3  7  3  3  3  0 -1\n",
      "  3  3  7  1  7  0  3  3  3  3  3  3  7  0  7  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  5  3 -1  3  3  3  3  3  7  3  3  3  3  3  6  3  3  3  3  6  3  6\n",
      "  3  3  3  3  3  2  3  3  7 -1  3  3  3  2  6  5  5  2  5  3  3  3  5  5\n",
      "  2  3  3  3  3  3  3  3  3 -1  7  3  3  3  3  3  3  3  3  3  3  3  5 -1\n",
      "  3  3  5  3  3 -1 -1 -1  2 -1 -1 -1  3  3  5 -1  3  5  5  0  3  3 -1  2]\n"
     ]
    }
   ],
   "source": [
    "# 📌 4️⃣ OOD 데이터 로드 & 전처리 (MFCC 특징 사용)\n",
    "ood_X_test = df_combined2.iloc[:, -50:]  # OOD 데이터의 MFCC 13개 컬럼 사용\n",
    "\n",
    "# 📌 5️⃣ Softmax 기반 OOD 탐지 함수\n",
    "def predict_with_ood_detection(model2, X, threshold=0.6):\n",
    "    probs = model2.predict_proba(X)  # Softmax 확률 출력\n",
    "    max_probs = np.max(probs, axis=1)  # 가장 높은 확률 값\n",
    "    preds = np.argmax(probs, axis=1)  # 가장 높은 확률의 클래스\n",
    "\n",
    "    # 특정 확률(threshold) 이하이면 \"기타 소음\"(-1)으로 변경\n",
    "    final_preds = np.where(max_probs < threshold, -1, preds)\n",
    "    \n",
    "    return final_preds\n",
    "\n",
    "# 📌 6️⃣ OOD 탐지 적용 (테스트 데이터 & 기타 소음 데이터)\n",
    "#y_pred_test = predict_with_ood_detection(model, X_test, threshold=0.8)\n",
    "y_pred_ood = predict_with_ood_detection(model2, ood_X_test, threshold=0.8)\n",
    "\n",
    "# NumPy 배열 출력 옵션 변경 (생략 없이 출력)\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "# 📌 7️⃣ 결과 출력\n",
    "#print(\"✅ 테스트 데이터 예측 결과:\", y_pred_test)\n",
    "print(\"✅ OOD (기타 소음) 예측 결과 (Softmax 기반 필터링):\", y_pred_ood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c80c43-742f-40c3-a73d-9112fd416a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
